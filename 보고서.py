import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
import altair as alt
import pickle

import sys
from datetime import datetime, timedelta
import pytz
import re

# --- í˜ì´ì§€ ì„¤ì • ë° ê¸°ë³¸ ìŠ¤íƒ€ì¼ ---
st.set_page_config(layout="wide")
st.markdown("""
<style>
    /* ê¸°ë³¸ í…Œì´ë¸” ìŠ¤íƒ€ì¼ */
    .custom_table {
        width: 100%;
        border-collapse: collapse;
        font-size: 0.9rem;
    }
    .custom_table th, .custom_table td {
        border: 1px solid #e0e0e0;
        padding: 8px;
        text-align: center;
    }
    .custom_table th {
        background-color: #f7f7f9;
        font-weight: bold;
    }
    .custom_table tr:nth-child(even) {
        background-color: #fafafa;
    }
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    .css-1d391kg {
        padding-top: 3rem;
    }
    /* ì¸ì‡„ ë˜ëŠ” PDF ìƒì„± ì‹œ ë¶ˆí•„ìš”í•œ UI ìˆ¨ê¸°ê¸° */
    @media print {
        /* ì‚¬ì´ë“œë°”ì™€ ëª¨ë“  no-print í´ë˜ìŠ¤ ìš”ì†Œ ìˆ¨ê¸°ê¸° */
        div[data-testid="stSidebar"], .no-print {
            display: none !important;
        }
        /* ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ íŒ¨ë”© ì¡°ì ˆ */
        .main .block-container {
            padding: 1rem !important;
        }
    }
</style>
""", unsafe_allow_html=True)

# --- ë°ì´í„° ë° ë©”ëª¨ ë¡œë”© í•¨ìˆ˜ ---
@st.cache_data(ttl=3600)
def load_data():
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open("preprocessed_data.pkl", "rb") as f:
            return pickle.load(f)
    except FileNotFoundError:
        st.error("ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼(preprocessed_data.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¨¼ì € 'ì „ì²˜ë¦¬.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        sys.exit()

def load_memo():
    """ì €ì¥ëœ ë©”ëª¨ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open("memo.txt", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

def create_korea_map_data():
    """ê°„ë‹¨í•œ í•œêµ­ ì§€ë„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # í•œêµ­ì˜ ì£¼ìš” ì§€ì—­ ë°ì´í„° (ê°„ì†Œí™”ëœ ë²„ì „)
    import numpy as np
    korea_data = {
        'region': [
            'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ',
            'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›ë„', 'ì¶©ì²­ë¶ë„', 'ì¶©ì²­ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì „ë¼ë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
        ],
        'lat': [
            37.5665, 35.1796, 35.8714, 37.4563, 35.1595, 36.3504, 35.5384,
            36.4870, 37.4138, 37.8228, 36.8000, 36.5184, 35.7175, 34.8679, 36.4919, 35.4606, 33.4996
        ],
        'lon': [
            126.9780, 129.0756, 128.6014, 126.7052, 126.8526, 127.3845, 129.3114,
            127.2822, 127.5183, 128.1555, 127.7000, 126.8000, 127.1530, 126.9910, 128.8889, 128.2132, 126.5312
        ],
        'value': np.random.randint(10, 1000, size=17).tolist()  # 10~999 ì‚¬ì´ ëœë¤ê°’
    }
    return pd.DataFrame(korea_data)

def create_simple_map_data(selected_region=None):
    """st.mapì„ ìœ„í•œ ê°„ë‹¨í•œ ì§€ë„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ê¸°ë³¸ ì„œìš¸ ì¤‘ì‹¬ ë°ì´í„°
    myData = {'lat': [37.56668], 'lon': [126.9784]}
    
    # ì„ íƒëœ ì§€ì—­ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì§€ì—­ì˜ ì¢Œí‘œë¡œ ë³€ê²½
    if selected_region and selected_region != "ì „ì²´":
        korea_map_df = create_korea_map_data()
        region_data = korea_map_df[korea_map_df['region'] == selected_region]
        if not region_data.empty:
            myData['lat'] = [region_data['lat'].values[0]]
            myData['lon'] = [region_data['lon'].values[0]]
    
    # ê³ ì •ëœ í¬ì¸íŠ¸ ìˆ˜ë¡œ ëœë¤ í¬ì¸íŠ¸ ì¶”ê°€
    point_count = 10  # ê³ ì •ëœ í¬ì¸íŠ¸ ìˆ˜
    
    # ì„ íƒëœ ì§€ì—­ ì£¼ë³€ì— ëœë¤ í¬ì¸íŠ¸ ì¶”ê°€
    for _ in range(point_count - 1):
        myData['lat'].append(myData['lat'][0] + np.random.randn() / 50.0)
        myData['lon'].append(myData['lon'][0] + np.random.randn() / 50.0)
    
    return myData

def create_admin_map_data(df_admin_coords, selected_sido=None, selected_sigungu=None):
    """í–‰ì •êµ¬ì—­ë³„ ìœ„ê²½ë„ ì¢Œí‘œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ë„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if df_admin_coords.empty:
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„œìš¸ ì¤‘ì‹¬ ë°ì´í„° ë°˜í™˜
        return {'lat': [37.56668], 'lon': [126.9784], 'size': [100]}
    
    # í•„í„°ë§ëœ ë°ì´í„°
    filtered_data = df_admin_coords.copy()
    
    if selected_sido and selected_sido != "ì „ì²´":
        filtered_data = filtered_data[filtered_data['ì‹œë„'] == selected_sido]
    
    if selected_sigungu and selected_sigungu != "ì „ì²´":
        # ì‹œêµ°êµ¬ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
        filtered_data = filtered_data[filtered_data['ì‹œêµ°êµ¬'].astype(str) == selected_sigungu]
    
    if filtered_data.empty:
        # í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„œìš¸ ì¤‘ì‹¬ ë°ì´í„° ë°˜í™˜
        return {'lat': [37.56668], 'lon': [126.9784], 'size': [100]}
    
    # ìœ„ë„, ê²½ë„ ë°ì´í„° ì¶”ì¶œ
    lat_list = filtered_data['ìœ„ë„'].tolist()
    lon_list = filtered_data['ê²½ë„'].tolist()
    
    # ê° ì‹œêµ°êµ¬ë³„ë¡œ ëœë¤ ë°ì´í„° ìƒì„± (10~1000 ì‚¬ì´)
    size_list = []
    for i in range(len(filtered_data)):
        # ì‹œêµ°êµ¬ë³„ë¡œ ê³ ìœ í•œ ëœë¤ê°’ ìƒì„± (ì‹œë“œ ê³ ì •ìœ¼ë¡œ ì¼ê´€ì„± ìœ ì§€)
        sigungu_name = str(filtered_data.iloc[i]['ì‹œêµ°êµ¬'])
        np.random.seed(hash(sigungu_name) % 2**32)  # ì‹œêµ°êµ¬ëª…ì„ ì‹œë“œë¡œ ì‚¬ìš©
        random_value = np.random.randint(10, 1001)  # 10~1000 ì‚¬ì´ ëœë¤ê°’
        size_list.append(random_value)
    
    # ê° ì‹œêµ°êµ¬ë³„ë¡œ ê³ ìœ í•œ ëœë¤ í¬ê¸° ë°ì´í„°ë§Œ ì‚¬ìš© (ì¶”ê°€ í¬ì¸íŠ¸ ìƒì„± ì œê±°)
    
    return {'lat': lat_list, 'lon': lon_list, 'size': size_list}

# --- ë°ì´í„° ë¡œë”© ---
data = load_data()
df = data["df"]
df_1 = data["df_1"]
df_2 = data["df_2"]
df_3 = data["df_3"]
df_4 = data["df_4"]
df_5 = data["df_5"]
df_sales = data["df_sales"]
df_fail_q3 = data["df_fail_q3"]
df_2_fail_q3 = data["df_2_fail_q3"]
update_time_str = data["update_time_str"]
df_admin_coords = data.get("df_admin_coords", pd.DataFrame())  # í–‰ì •êµ¬ì—­ë³„ ìœ„ê²½ë„ ì¢Œí‘œ ë°ì´í„°
df_master = data.get("df_master", pd.DataFrame())  # ì§€ìì²´ ì •ë¦¬ master.xlsx ë°ì´í„°

# --- ì‹œê°„ëŒ€ ì„¤ì • ---
KST = pytz.timezone('Asia/Seoul')
today_kst = datetime.now(KST).date()

# --- ì‚¬ì´ë“œë°”: ì¡°íšŒ ì˜µì…˜ ì„¤ì • ---
with st.sidebar:
    st.header("ğŸ‘ï¸ ë·°ì–´ ì˜µì…˜")
    viewer_option = st.radio("ë·°ì–´ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.", ('ë‚´ë¶€', 'í…ŒìŠ¬ë¼', 'í´ìŠ¤íƒ€', 'ì§€ë„(í…ŒìŠ¤íŠ¸)', 'ì§€ìì²´ë³„ ì •ë¦¬'), key="viewer_option")
    st.markdown("---")
    st.header("ğŸ“Š ì¡°íšŒ ì˜µì…˜")
    view_option = st.radio(
        "ì¡°íšŒ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.",
        ('ê¸ˆì¼', 'íŠ¹ì •ì¼ ì¡°íšŒ', 'ê¸°ê°„ë³„ ì¡°íšŒ', 'ë¶„ê¸°ë³„ ì¡°íšŒ', 'ì›”ë³„ ì¡°íšŒ', 'ì „ì²´ ëˆ„ì '),
        key="view_option"
    )

    start_date, end_date = None, None
    title = f"{view_option} ë¦¬í¬íŠ¸"

    if view_option == 'ê¸ˆì¼':
        start_date = end_date = today_kst
    elif view_option == 'íŠ¹ì •ì¼ ì¡°íšŒ':
        # 6ì›” 24ì¼ë¶€í„°ë§Œ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡ ìµœì†Œ ë‚ ì§œ ì œí•œ ì„¤ì •
        earliest_date = datetime(today_kst.year, 6, 24).date()
        # ë§Œì•½ ì˜¤ëŠ˜ì´ 6ì›” 24ì¼ ì´ì „ì´ë¼ë©´ ì „ë…„ë„ 6ì›” 24ì¼ì„ ìµœì†Œê°’ìœ¼ë¡œ ì‚¬ìš©
        if today_kst < earliest_date:
            earliest_date = datetime(today_kst.year - 1, 6, 24).date()
        selected_date = st.date_input(
            'ë‚ ì§œ ì„ íƒ',
            value=max(today_kst, earliest_date),
            min_value=earliest_date,
            max_value=today_kst
        )
        start_date = end_date = selected_date
        title = f"{selected_date.strftime('%Y-%m-%d')} ë¦¬í¬íŠ¸"
    elif view_option == 'ê¸°ê°„ë³„ ì¡°íšŒ':
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input('ì‹œì‘ì¼', value=today_kst.replace(day=1))
        with col2:
            end_date = st.date_input('ì¢…ë£Œì¼', value=today_kst)
        if start_date > end_date:
            st.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
        title = f"{start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ë¦¬í¬íŠ¸"
    elif view_option == 'ë¶„ê¸°ë³„ ì¡°íšŒ':
        year = today_kst.year
        quarter = st.selectbox('ë¶„ê¸° ì„ íƒ', [f'{q}ë¶„ê¸°' for q in range(1, 5)], index=(today_kst.month - 1) // 3)
        q_num = int(quarter[0])
        start_month = 3 * q_num - 2
        end_month = 3 * q_num
        start_date = datetime(year, start_month, 1).date()
        end_day = (datetime(year, end_month % 12 + 1, 1) - timedelta(days=1)).day if end_month < 12 else 31
        end_date = datetime(year, end_month, end_day).date()
        title = f"{year}ë…„ {quarter} ë¦¬í¬íŠ¸"
    elif view_option == 'ì›”ë³„ ì¡°íšŒ':
        year = today_kst.year
        month = st.selectbox('ì›” ì„ íƒ', [f'{m}ì›”' for m in range(1, 13)], index=today_kst.month - 1)
        month_num = int(month[:-1])
        start_date = datetime(year, month_num, 1).date()
        end_day = (datetime(year, (month_num % 12) + 1, 1) - timedelta(days=1)).day if month_num < 12 else 31
        end_date = datetime(year, month_num, end_day).date()
        title = f"{year}ë…„ {month} ë¦¬í¬íŠ¸"
    elif view_option == 'ì „ì²´ ëˆ„ì ':
        min_date_1 = df_1['ë‚ ì§œ'].min().date() if not df_1.empty else today_kst
        min_date_5 = df_5['ë‚ ì§œ'].min().date() if not df_5.empty else today_kst
        start_date = min(min_date_1, min_date_5)
        end_date = today_kst
        title = "ì „ì²´ ëˆ„ì  ë¦¬í¬íŠ¸"

    # ì›”ë³„ ìš”ì•½ì€ í•­ìƒ í‘œì‹œ
    show_monthly_summary = True

    st.markdown("---")
    st.header("ğŸ“ ë©”ëª¨")
    memo_content = load_memo()
    new_memo = st.text_area(
        "ë©”ëª¨ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì„¸ìš”.",
        value=memo_content, height=250, key="memo_input"
    )
    if new_memo != memo_content:
        with open("memo.txt", "w", encoding="utf-8") as f:
            f.write(new_memo)
        st.toast("ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---
st.title(title)
st.caption(f"ë§ˆì§€ë§‰ ë°ì´í„° ì—…ë°ì´íŠ¸: {update_time_str}")
st.markdown("---")

# --- ê³„ì‚° í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def get_corporate_metrics(df3_raw, df4_raw, start, end):
    """ê¸°ê°„ ë‚´ ë²•ì¸íŒ€ ì‹¤ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # ì§€ì› (íŒŒì´í”„ë¼ì¸, ì§€ì›ì‹ ì²­)
    pipeline, apply = 0, 0
    df3 = df3_raw.copy()
    date_col_3 = 'ì‹ ì²­ ìš”ì²­ì¼'
    if not pd.api.types.is_datetime64_any_dtype(df3[date_col_3]):
        df3[date_col_3] = pd.to_datetime(df3[date_col_3], errors='coerce')
    
    mask3 = (df3[date_col_3].dt.date >= start) & (df3[date_col_3].dt.date <= end)
    df3_period = df3.loc[mask3].dropna(subset=[date_col_3])

    df3_period = df3_period[df3_period['ì ‘ìˆ˜ ì™„ë£Œ'].astype(str).str.strip().isin(['O', 'ã…‡'])]
    if 'ê·¸ë¦¬íŠ¸ ë…¸íŠ¸' in df3_period.columns:
        is_cancelled = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ', na=False)
        is_reapplied = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ í›„ ì¬ì‹ ì²­', na=False)
        df3_period = df3_period[~(is_cancelled & ~is_reapplied)]
    
    b_col_name = df3_period.columns[1]
    df3_period = df3_period[df3_period[b_col_name].notna() & (df3_period[b_col_name] != "")]

    pipeline = int(df3_period['ì‹ ì²­ëŒ€ìˆ˜'].sum())
    mask_bulk_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] > 1
    mask_single_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] == 1
    apply = int(mask_bulk_3.sum() + df3_period.loc[mask_single_3, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())

    # ì§€ê¸‰ (ì§€ê¸‰ì‹ ì²­)
    distribute = 0
    df4 = df4_raw.copy()
    date_col_4 = 'ìš”ì²­ì¼ì'
    if not pd.api.types.is_datetime64_any_dtype(df4[date_col_4]):
        df4[date_col_4] = pd.to_datetime(df4[date_col_4], errors='coerce')

    mask4 = (df4[date_col_4].dt.date >= start) & (df4[date_col_4].dt.date <= end)
    df4_period = df4.loc[mask4].dropna(subset=[date_col_4])
    
    df4_period = df4_period[df4_period['ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€'].astype(str).str.strip() == 'ì™„ë£Œ']
    unique_df4_period = df4_period.drop_duplicates(subset=['ì‹ ì²­ë²ˆí˜¸'])

    mask_bulk_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1
    mask_single_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1
    distribute = int(mask_bulk_4.sum() + unique_df4_period.loc[mask_single_4, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())

    return {'pipeline': pipeline, 'apply': apply, 'distribute': distribute}

# --- ì‹¤ì  ê³„ì‚° ---
corporate_metrics = get_corporate_metrics(df_3, df_4, start_date, end_date)

# --- íŠ¹ì´ì‚¬í•­ ì¶”ì¶œ ---
def extract_special_memo(df_fail_q3, today):
    """
    ì˜¤ëŠ˜ ë‚ ì§œì˜ df_fail_q3ì—ì„œ 'Greet Note'ë³„ ê±´ìˆ˜ë¥¼ ['ë‚´ìš©', 'ê±´ìˆ˜'] í˜•íƒœë¡œ í•œ ì¤„ì”© ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 'ë‚ ì§œ' ì»¬ëŸ¼ì´ datetimeì´ ì•„ë‹ ê²½ìš° ë³€í™˜
    if not pd.api.types.is_datetime64_any_dtype(df_fail_q3['ë‚ ì§œ']):
        df_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_fail_q3['ë‚ ì§œ'], errors='coerce')
    # ì˜¤ëŠ˜ ë‚ ì§œ í•„í„°ë§
    today_fail = df_fail_q3[df_fail_q3['ë‚ ì§œ'].dt.date == today]
    # 'Greet Note' ì»¬ëŸ¼ëª…ì„ ìœ ì—°í•˜ê²Œ ì°¾ê¸° (ê³µë°±Â·ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    lowered_cols = {c.lower().replace(' ', ''): c for c in today_fail.columns}
    # 'greetnote' ë˜ëŠ” 'ë…¸íŠ¸' í‚¤ì›Œë“œ í¬í•¨ ì»¬ëŸ¼ íƒìƒ‰
    note_col = next((orig for key, orig in lowered_cols.items() if 'greetnote' in key or 'ë…¸íŠ¸' in key), None)
    if note_col is None:
        return []
    # value_counts
    note_counts = today_fail[note_col].astype(str).value_counts().reset_index()
    note_counts.columns = ['ë‚´ìš©', 'ê±´ìˆ˜']
    # í•œ ì¤„ì”© ë©”ëª¨ í˜•íƒœë¡œ ë³€í™˜
    memo_lines = [f"{row['ë‚´ìš©']}: {row['ê±´ìˆ˜']}ê±´" for _, row in note_counts.iterrows()]
    return memo_lines

# --- ëŒ€ì‹œë³´ë“œ í‘œì‹œ ---
col1_top, col2_top, col3_top = st.columns([3.5, 2, 1.5])

with col1_top:
    st.write("### 1. ë¦¬í…Œì¼ ê¸ˆì¼/ì „ì¼ ìš”ì•½")

    selected_date = end_date
    day0 = selected_date
    day1 = (pd.to_datetime(selected_date) - pd.tseries.offsets.BDay(1)).date()

    year = selected_date.year
    q3_start_default = datetime(year, 6, 24).date()
    q3_start_distribute = datetime(year, 7, 1).date()

    cnt_today_mail = (df_5['ë‚ ì§œ'].dt.date == day0).sum()
    cnt_yesterday_mail = (df_5['ë‚ ì§œ'].dt.date == day1).sum()
    cnt_total_mail = ((df_5['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_5['ë‚ ì§œ'].dt.date <= day0)).sum()

    cnt_today_apply = int(df_1.loc[df_1['ë‚ ì§œ'].dt.date == day0, 'ê°œìˆ˜'].sum())
    cnt_yesterday_apply = int(df_1.loc[df_1['ë‚ ì§œ'].dt.date == day1, 'ê°œìˆ˜'].sum())
    cnt_total_apply = int(df_1.loc[(df_1['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_1['ë‚ ì§œ'].dt.date <= day0), 'ê°œìˆ˜'].sum())

    cnt_today_distribute = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day0, 'ë°°ë¶„'].sum())
    cnt_yesterday_distribute = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day1, 'ë°°ë¶„'].sum())
    cnt_total_distribute = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= day0), 'ë°°ë¶„'].sum())

    cnt_today_request = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day0, 'ì‹ ì²­'].sum())
    cnt_yesterday_request = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day1, 'ì‹ ì²­'].sum())
    cnt_total_request = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= day0), 'ì‹ ì²­'].sum())

    if not pd.api.types.is_datetime64_any_dtype(df_fail_q3['ë‚ ì§œ']):
        df_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_fail_q3['ë‚ ì§œ'], errors='coerce')
    if not pd.api.types.is_datetime64_any_dtype(df_2_fail_q3['ë‚ ì§œ']):
        df_2_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_2_fail_q3['ë‚ ì§œ'], errors='coerce')

    cnt_yesterday_fail = int((df_fail_q3['ë‚ ì§œ'].dt.date == day1).sum())
    cnt_today_fail = int((df_fail_q3['ë‚ ì§œ'].dt.date == day0).sum())
    cnt_total_fail = int(((df_fail_q3['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_fail_q3['ë‚ ì§œ'].dt.date <= day0)).sum())

    cnt_yesterday_fail_2 = int(df_2_fail_q3.loc[df_2_fail_q3['ë‚ ì§œ'].dt.date == day1, 'ë¯¸ì‹ ì²­ê±´'].sum())
    cnt_today_fail_2 = int(df_2_fail_q3.loc[df_2_fail_q3['ë‚ ì§œ'].dt.date == day0, 'ë¯¸ì‹ ì²­ê±´'].sum())
    cnt_total_fail_2 = int(df_2_fail_q3.loc[(df_2_fail_q3['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_2_fail_q3['ë‚ ì§œ'].dt.date <= day0), 'ë¯¸ì‹ ì²­ê±´'].sum())

    delta_mail = cnt_today_mail - cnt_yesterday_mail
    delta_apply = cnt_today_apply - cnt_yesterday_apply
    delta_fail = cnt_today_fail - cnt_yesterday_fail
    delta_distribute = cnt_today_distribute - cnt_yesterday_distribute
    delta_request = cnt_today_request - cnt_yesterday_request
    delta_fail_2 = cnt_today_fail_2 - cnt_yesterday_fail_2

    def format_delta(value):
        if value > 0: return f'<span style="color:blue;">+{value}</span>'
        elif value < 0: return f'<span style="color:red;">{value}</span>'
        return str(value)

    table_data = pd.DataFrame({
        ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ë©”ì¼ ê±´ìˆ˜'): [cnt_yesterday_mail, cnt_today_mail, cnt_total_mail],
        ('ì§€ì›', 'ì‹ ì²­', 'ì‹ ì²­ ê±´ìˆ˜'): [cnt_yesterday_apply, cnt_today_apply, cnt_total_apply],
        ('ì§€ì›', 'ì‹ ì²­', 'ë¯¸ì‹ ì²­ê±´'): [cnt_yesterday_fail, cnt_today_fail, cnt_total_fail],
        ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ì§€ê¸‰ ë°°ë¶„ê±´'): [cnt_yesterday_distribute, cnt_today_distribute, cnt_total_distribute],
        ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ì§€ê¸‰ì‹ ì²­ ê±´ìˆ˜'): [cnt_yesterday_request, cnt_today_request, cnt_total_request],
        ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ë¯¸ì‹ ì²­ê±´'): [cnt_yesterday_fail_2, cnt_today_fail_2, cnt_total_fail_2]
    }, index=[f'ì „ì¼ ({day1})', f'ê¸ˆì¼ ({day0})', 'ëˆ„ì  ì´ê³„ (3ë¶„ê¸°)'])

    table_data.loc['ë³€ë™'] = [
        format_delta(delta_mail),
        format_delta(delta_apply),
        format_delta(delta_fail),
        format_delta(delta_distribute),
        format_delta(delta_request),
        format_delta(delta_fail_2)
    ]
    html_table = table_data.to_html(classes='custom_table', border=0, escape=False)
    st.markdown(html_table, unsafe_allow_html=True)

with col2_top:
    st.write("### 2. ë²•ì¸íŒ€ ê¸ˆì¼ ìš”ì•½")
    
    required_cols_df3 = ['ì‹ ì²­ ìš”ì²­ì¼', 'ì ‘ìˆ˜ ì™„ë£Œ', 'ì‹ ì²­ëŒ€ìˆ˜']
    required_cols_df4 = ['ìš”ì²­ì¼ì', 'ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€', 'ì‹ ì²­ë²ˆí˜¸', 'ì ‘ìˆ˜ëŒ€ìˆ˜']
    has_all_cols = all(col in df_3.columns for col in required_cols_df3) and \
                   all(col in df_4.columns for col in required_cols_df4)

    if has_all_cols:
        # (ê¸°ì¡´ ë²•ì¸íŒ€ ê³„ì‚° í•¨ìˆ˜ë“¤)
        def process_new(df, end_date):
            df = df.copy()
            date_col = 'ì‹ ì²­ ìš”ì²­ì¼'
            if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
            df_cumulative = df[df[date_col].notna() & (df[date_col].dt.date <= end_date)]
            df_cumulative = df_cumulative[df_cumulative['ì ‘ìˆ˜ ì™„ë£Œ'].astype(str).str.strip().isin(['O', 'ã…‡'])]
            if 'ê·¸ë¦¬íŠ¸ ë…¸íŠ¸' in df_cumulative.columns:
                is_cancelled = df_cumulative['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ', na=False)
                is_reapplied = df_cumulative['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ í›„ ì¬ì‹ ì²­', na=False)
                df_cumulative = df_cumulative[~(is_cancelled & ~is_reapplied)]
            b_col_name = df_cumulative.columns[1]
            df_cumulative = df_cumulative[df_cumulative[b_col_name].notna() & (df_cumulative[b_col_name] != "")]
            df_today = df_cumulative[df_cumulative[date_col].dt.date == end_date]

            mask_bulk = df_cumulative['ì‹ ì²­ëŒ€ìˆ˜'] > 1
            mask_single = df_cumulative['ì‹ ì²­ëŒ€ìˆ˜'] == 1

            new_bulk_sum = int(df_cumulative.loc[mask_bulk, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())
            new_single_sum = int(df_cumulative.loc[mask_single, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())
            new_bulk_count = int(mask_bulk.sum())
            today_bulk_count = int((df_today['ì‹ ì²­ëŒ€ìˆ˜'] > 1).sum())
            today_single_count = int((df_today['ì‹ ì²­ëŒ€ìˆ˜'] == 1).sum())

            return new_bulk_sum, new_single_sum, new_bulk_count, today_bulk_count, today_single_count

        def process_give(df, end_date):
            df = df.copy()
            date_col = 'ìš”ì²­ì¼ì'
            if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
            df_cumulative = df[df[date_col].notna() & (df[date_col].dt.date <= end_date)]
            df_cumulative = df_cumulative[df_cumulative['ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€'].astype(str).str.strip() == 'ì™„ë£Œ']
            unique_df_cumulative = df_cumulative.drop_duplicates(subset=['ì‹ ì²­ë²ˆí˜¸'])
            df_today = unique_df_cumulative[unique_df_cumulative[date_col].dt.date == end_date]

            mask_bulk = unique_df_cumulative['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1
            mask_single = unique_df_cumulative['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1

            give_bulk_sum = int(unique_df_cumulative.loc[mask_bulk, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())
            give_single_sum = int(unique_df_cumulative.loc[mask_single, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())
            give_bulk_count = int(mask_bulk.sum())
            give_today_bulk_count = int((df_today['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1).sum())
            give_today_single_count = int((df_today['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1).sum())

            return give_bulk_sum, give_single_sum, give_bulk_count, give_today_bulk_count, give_today_single_count

        new_bulk_sum, new_single_sum, new_bulk_count, new_today_bulk_count, new_today_single_count = process_new(df_3, selected_date)
        give_bulk_sum, give_single_sum, give_bulk_count, give_today_bulk_count, give_today_single_count = process_give(df_4, selected_date)

        row_names = ['ë²Œí¬', 'ë‚±ê°œ', 'TTL']
        columns = pd.MultiIndex.from_tuples([
            ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜'), ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼'), ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„'),
            ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜'), ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼'), ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')
        ], names=['', 'ë¶„ë¥˜', 'í•­ëª©'])
        df_total = pd.DataFrame(0, index=row_names, columns=columns)

        df_total.loc['ë²Œí¬', ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = new_bulk_sum
        df_total.loc['ë‚±ê°œ', ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = new_single_sum
        df_total.loc['TTL', ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = new_bulk_sum + new_single_sum
        df_total.loc['ë²Œí¬', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = new_today_bulk_count
        df_total.loc['ë‚±ê°œ', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = new_today_single_count
        df_total.loc['TTL', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = new_today_bulk_count + new_today_single_count
        df_total.loc['ë²Œí¬', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = new_bulk_count
        df_total.loc['ë‚±ê°œ', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = new_single_sum
        df_total.loc['TTL', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = new_bulk_count + new_single_sum
        df_total.loc['ë²Œí¬', ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = give_bulk_sum
        df_total.loc['ë‚±ê°œ', ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = give_single_sum
        df_total.loc['TTL', ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = give_bulk_sum + give_single_sum
        df_total.loc['ë²Œí¬', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = give_today_bulk_count
        df_total.loc['ë‚±ê°œ', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = give_today_single_count
        df_total.loc['TTL', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = give_today_bulk_count + give_today_single_count
        df_total.loc['ë²Œí¬', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = give_bulk_count
        df_total.loc['ë‚±ê°œ', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = give_single_sum
        df_total.loc['TTL', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = give_bulk_count + give_single_sum

        html_table_corp = df_total.to_html(classes='custom_table', border=0)
        st.markdown(html_table_corp, unsafe_allow_html=True)
    else:
        st.warning("ë²•ì¸íŒ€ ì‹¤ì ì„ ê³„ì‚°í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

with col3_top:
    st.subheader("ë¯¸ì‹ ì²­ê±´")

    auto_special_lines = extract_special_memo(df_fail_q3, selected_date)
    if not auto_special_lines:
        auto_special_lines = ["ë¯¸ì‹ ì²­ê±´ ì—†ìŒ"]
    auto_special_text = "\n".join(auto_special_lines)

    def load_memo_file(path:str):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            return ""
    memo_special_saved = load_memo_file("memo_special.txt")

    default_special = auto_special_text
    if memo_special_saved.strip():
        default_special += ("\n" if default_special else "") + memo_special_saved.strip()

    st.markdown(
        f"<div style='font-size:16px; white-space:pre-wrap; background-color:#e0f7fa; border-radius:8px; padding:10px; min-height: 200px;'><b>{default_special}</b></div>",
        unsafe_allow_html=True,
    )

# 2. í†µí•© êµ¬ë¶„ì„  ì¶”ê°€
st.markdown("<hr style='margin:1rem 0; border:1px solid #e0e0e0;'>", unsafe_allow_html=True)

# 3. í•˜ë‹¨ í–‰(Row) ìƒì„±
col1_bottom, col2_bottom, col3_bottom = st.columns([3.5, 2, 1.5])

with col1_bottom:
    header_col, sel_col = st.columns([4,2])
    with header_col:
        st.write("##### ë¦¬í…Œì¼ ì›”ë³„ ìš”ì•½")
    with sel_col:
        period_option = st.selectbox(
            'ê¸°ê°„ ì„ íƒ',
            ['3Q', '7ì›”', 'ì „ì²´', '1Q', '2Q'] + [f'{m}ì›”' for m in range(1,13)],
            index=0,
            key='retail_period')

    # (ë¦¬í…Œì¼ ì›”ë³„ ìš”ì•½ í…Œì´ë¸” ë° ê·¸ë˜í”„ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    # --- ì›”ë³„/ë¶„ê¸°ë³„ ìš”ì•½ ê³„ì‚° ---
    current_year = day0.year
    june_23 = datetime(current_year, 6, 23).date()
    june_24 = datetime(current_year, 6, 24).date()
    july_1 = datetime(current_year, 7, 1).date()
    july_31 = datetime(current_year, 7, 31).date()
    august_1 = datetime(current_year, 8, 1).date()
    september_1 = datetime(current_year, 9, 1).date()
    retail_df = pd.DataFrame()
    if period_option == 'ì „ì²´':
        q1_total_mail = int(df_5[df_5['ë‚ ì§œ'].dt.month.isin([1,2,3])].shape[0])
        q1_total_apply = int(df_1[df_1['ë‚ ì§œ'].dt.month.isin([1,2,3])]['ê°œìˆ˜'].sum())
        q1_total_distribute = int(df_2[df_2['ë‚ ì§œ'].dt.month.isin([1,2,3])]['ë°°ë¶„'].sum())
        q2_total_mail = int(df_5[df_5['ë‚ ì§œ'].dt.month.isin([4,5,6])].shape[0])
        q2_apply_mask = (df_1['ë‚ ì§œ'].dt.month.isin([4,5])) | ((df_1['ë‚ ì§œ'].dt.month == 6) & (df_1['ë‚ ì§œ'].dt.date <= june_23))
        q2_total_apply = int(df_1[q2_apply_mask]['ê°œìˆ˜'].sum())
        q2_total_distribute = int(df_2[df_2['ë‚ ì§œ'].dt.month.isin([4,5,6])]['ë°°ë¶„'].sum())
        july_mail_total = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= june_24) & (df_5['ë‚ ì§œ'].dt.date <= july_31)].shape[0])
        july_apply_total = int(df_1[(df_1['ë‚ ì§œ'].dt.date >= june_24) & (df_1['ë‚ ì§œ'].dt.date <= july_31)]['ê°œìˆ˜'].sum())
        july_distribute_total = int(df_2[(df_2['ë‚ ì§œ'].dt.date >= july_1) & (df_2['ë‚ ì§œ'].dt.date <= july_31)]['ë°°ë¶„'].sum())
        august_cumulative_mail = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= august_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0])
        august_cumulative_apply = int(df_1[(df_1['ë‚ ì§œ'].dt.date >= august_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum())
        august_cumulative_distribute = int(df_2[(df_2['ë‚ ì§œ'].dt.date >= august_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
        september_cumulative_mail = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= september_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0])
        september_cumulative_apply = int(df_1[(df_1['ë‚ ì§œ'].dt.date >= september_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum())
        september_cumulative_distribute = int(df_2[(df_2['ë‚ ì§œ'].dt.date >= september_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
        q3_total_mail = july_mail_total + august_cumulative_mail + september_cumulative_mail
        q3_total_apply = july_apply_total + august_cumulative_apply + september_cumulative_apply
        q3_total_distribute = july_distribute_total + august_cumulative_distribute + september_cumulative_distribute
        q1_target, q2_target, q3_target = 4300, 10000, 10000
        q1_progress = q1_total_mail / q1_target if q1_target > 0 else 0
        q2_progress = q2_total_mail / q2_target if q2_target > 0 else 0
        q3_progress = q3_total_mail / q3_target if q3_target > 0 else 0
        retail_df_data = {
            'Q1': [q1_target, q1_total_mail, q1_total_apply, f"{q1_progress:.1%}", '', q1_total_distribute],
            'Q2': [q2_target, q2_total_mail, q2_total_apply, f"{q2_progress:.1%}", '', q2_total_distribute],
            'Q3': [q3_target, q3_total_mail, q3_total_apply, f"{q3_progress:.1%}", '', q3_total_distribute]
        }
        retail_index = ['íƒ€ê²Ÿ', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì§„ì²™ë¥ ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­']
        retail_df = pd.DataFrame(retail_df_data, index=retail_index)
    # (ì´í•˜ ê¸°ê°„ ì„ íƒ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ)
    elif period_option in ('3Q', '3ë¶„ê¸°'):
        q3_monthly_data = {}
        q3_monthly_data['7'] = [
            int(df_5[(df_5['ë‚ ì§œ'].dt.date >= june_24) & (df_5['ë‚ ì§œ'].dt.date <= july_31)].shape[0]),
            int(df_1[(df_1['ë‚ ì§œ'].dt.date >= june_24) & (df_1['ë‚ ì§œ'].dt.date <= july_31)]['ê°œìˆ˜'].sum()),
            int(df_2[(df_2['ë‚ ì§œ'].dt.date >= july_1) & (df_2['ë‚ ì§œ'].dt.date <= july_31)]['ë°°ë¶„'].sum())
        ]
        q3_monthly_data['8'] = [
            int(df_5[(df_5['ë‚ ì§œ'].dt.date >= august_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0]),
            int(df_1[(df_1['ë‚ ì§œ'].dt.date >= august_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum()),
            int(df_2[(df_2['ë‚ ì§œ'].dt.date >= august_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
        ]
        q3_monthly_data['9'] = [
            int(df_5[(df_5['ë‚ ì§œ'].dt.date >= september_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0]),
            int(df_1[(df_1['ë‚ ì§œ'].dt.date >= september_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum()),
            int(df_2[(df_2['ë‚ ì§œ'].dt.date >= september_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
        ]
        q3_total_mail = sum(q3_monthly_data[m][0] for m in ['7', '8', '9'])
        q3_total_apply = sum(q3_monthly_data[m][1] for m in ['7', '8', '9'])
        q3_total_distribute = sum(q3_monthly_data[m][2] for m in ['7', '8', '9'])
        q3_target = 10000
        q3_progress = q3_total_mail / q3_target if q3_target > 0 else 0
        retail_df_data = {
            '7': [q3_target, q3_monthly_data['7'][0], q3_monthly_data['7'][1], f"{q3_progress:.1%}", '', q3_monthly_data['7'][2]],
            '8': ['', q3_monthly_data['8'][0], q3_monthly_data['8'][1], '', '', q3_monthly_data['8'][2]],
            '9': ['', q3_monthly_data['9'][0], q3_monthly_data['9'][1], '', '', q3_monthly_data['9'][2]],
            'ê³„': [q3_target, q3_total_mail, q3_total_apply, f"{q3_progress:.1%}", '', q3_total_distribute]
        }
        retail_index = ['íƒ€ê²Ÿ', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì§„ì²™ë¥ ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­']
        retail_df = pd.DataFrame(retail_df_data, index=retail_index)
    html_retail = retail_df.to_html(classes='custom_table', border=0, escape=False)
    st.markdown(html_retail, unsafe_allow_html=True)

with col2_bottom:
    if show_monthly_summary:
        if viewer_option == 'ë‚´ë¶€':
            header_corp, sel_corp = st.columns([4,2])
            with header_corp:
                st.write("##### ë²•ì¸íŒ€ ì›”ë³„ ìš”ì•½")
        else:
            st.write("##### ë²•ì¸íŒ€ ì›”ë³„ ìš”ì•½")
    
        # (ë²•ì¸íŒ€ ì›”ë³„ ìš”ì•½ í…Œì´ë¸” ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
        year = today_kst.year
        q3_apply_start = datetime(year, 6, 18).date()
        q3_distribute_start = datetime(year, 6, 18).date()
        july_end = datetime(year, 7, 31).date()
        august_start = datetime(year, 8, 1).date()
        august_end = datetime(year, 8, 31).date()
        def get_corp_period_metrics(df3_raw, df4_raw, apply_start, apply_end, distribute_start, distribute_end):
            pipeline, apply, distribute = 0, 0, 0
            df3 = df3_raw.copy()
            date_col_3 = 'ì‹ ì²­ ìš”ì²­ì¼'
            if not pd.api.types.is_datetime64_any_dtype(df3[date_col_3]):
                df3[date_col_3] = pd.to_datetime(df3[date_col_3], errors='coerce')
            mask3 = (df3[date_col_3].dt.date >= apply_start) & (df3[date_col_3].dt.date <= apply_end)
            df3_period = df3.loc[mask3]
            df3_period = df3_period[df3_period['ì ‘ìˆ˜ ì™„ë£Œ'].astype(str).str.strip().isin(['O', 'ã…‡'])]
            if 'ê·¸ë¦¬íŠ¸ ë…¸íŠ¸' in df3_period.columns:
                is_cancelled = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ', na=False)
                is_reapplied = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ í›„ ì¬ì‹ ì²­', na=False)
                df3_period = df3_period[~(is_cancelled & ~is_reapplied)]
            b_col_name = df3_period.columns[1]
            df3_period = df3_period[df3_period[b_col_name].notna() & (df3_period[b_col_name] != "")]
            pipeline = int(df3_period['ì‹ ì²­ëŒ€ìˆ˜'].sum())
            mask_bulk_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] > 1
            mask_single_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] == 1
            apply = int(mask_bulk_3.sum() + df3_period.loc[mask_single_3, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())
            df4 = df4_raw.copy()
            date_col_4 = 'ìš”ì²­ì¼ì'
            if not pd.api.types.is_datetime64_any_dtype(df4[date_col_4]):
                df4[date_col_4] = pd.to_datetime(df4[date_col_4], errors='coerce')
            mask4 = (df4[date_col_4].dt.date >= distribute_start) & (df4[date_col_4].dt.date <= distribute_end)
            df4_period = df4.loc[mask4]
            df4_period = df4_period[df4_period['ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€'].astype(str).str.strip() == 'ì™„ë£Œ']
            unique_df4_period = df4_period.drop_duplicates(subset=['ì‹ ì²­ë²ˆí˜¸'])
            mask_bulk_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1
            mask_single_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1
            distribute = int(mask_bulk_4.sum() + unique_df4_period.loc[mask_single_4, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())
            return pipeline, apply, distribute
        july_pipeline, july_apply, july_distribute = get_corp_period_metrics(df_3, df_4, q3_apply_start, july_end, q3_distribute_start, july_end)
        august_pipeline, august_apply, august_distribute = get_corp_period_metrics(df_3, df_4, august_start, august_end, august_start, august_end)
        corp_df_data = {'7ì›”': [july_pipeline, july_apply, july_distribute], '8ì›”': [august_pipeline, august_apply, august_distribute]}
        corp_df = pd.DataFrame(corp_df_data, index=['íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­', 'ì§€ê¸‰ì‹ ì²­'])
        corp_df['TTL'] = corp_df['7ì›”'] + corp_df['8ì›”']
        q3_target_corp = 1500
        ttl_apply_corp = corp_df.loc['ì§€ì›ì‹ ì²­', 'TTL']
        progress_rate_corp = ttl_apply_corp / q3_target_corp if q3_target_corp > 0 else 0
        formatted_progress_corp = f"{progress_rate_corp:.2%}"
        corp_df['Q3 Target'] = ''
        corp_df.loc['íŒŒì´í”„ë¼ì¸', 'Q3 Target'] = f"{q3_target_corp}"
        corp_df.loc['ì§€ì›ì‹ ì²­', 'Q3 Target'] = 'ì§„ì²™ë¥ '
        corp_df.loc['ì§€ê¸‰ì‹ ì²­', 'Q3 Target'] = formatted_progress_corp
        html_corp = corp_df.to_html(classes='custom_table', border=0, escape=False)
        html_corp = html_corp.replace('<td>ì§„ì²™ë¥ </td>', '<td style="background-color: #e0f7fa;">ì§„ì²™ë¥ </td>').replace(f'<td>{formatted_progress_corp}</td>', f'<td>{formatted_progress_corp}</td>')
        st.markdown(html_corp, unsafe_allow_html=True)

with col3_bottom:
    st.subheader("ê¸°íƒ€")
    def load_memo_file(path:str):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            return ""

    def save_memo_file(path:str, content:str):
        with open(path, "w", encoding="utf-8") as f:
            f.write(content)

    memo_etc = load_memo_file("memo_etc.txt")
    new_etc = st.text_area(
        "ê¸°íƒ€ë©”ëª¨",
        value=memo_etc,
        height=150,
        key="memo_etc_input"
    )
    if new_etc != memo_etc:
        save_memo_file("memo_etc.txt", new_etc)
        st.toast("ê¸°íƒ€ ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")


# --- í´ìŠ¤íƒ€ ë·° ì „ìš© í‘œ ---
if viewer_option == 'í´ìŠ¤íƒ€':
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    pol_data = {
        '1ì›”': [72, 0, 68, 4],
        '2ì›”': [52, 27, 25, 0],
        '3ì›”': [279, 249, 20, 10],
        '4ì›”': [182, 146, 16, 20],
        '5ì›”': [332, 246, 63, 23],
        '6ì›”': [47, 29, 11, 7],
        'í•©ê³„': [964, 697, 203, 64],
        '7ì›”': [140, 83, 48, 9],
        '8ì›”': [np.nan, np.nan, np.nan, np.nan],
        '9ì›”': [np.nan, np.nan, np.nan, np.nan],
        '10ì›”': [np.nan, np.nan, np.nan, np.nan],
        '11ì›”': [np.nan, np.nan, np.nan, np.nan],
        '12ì›”': [np.nan, np.nan, np.nan, np.nan],
        'í•©ê³„': [140, 83, 48, 9],
        '2025 ì´í•©': [1104, 780, 251, 73]
    }
    row_idx = ['íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­', 'í´ìŠ¤íƒ€ ë‚´ë¶€ì§€ì›', 'ì ‘ìˆ˜ í›„ ì·¨ì†Œ']
    pol_df = pd.DataFrame(pol_data, index=row_idx)

    st.title("í´ìŠ¤íƒ€ 2025")
    # NaN ê°’ì„ '-'ë¡œ ì¹˜í™˜
    html_pol = pol_df.fillna('-').to_html(classes='custom_table', border=0, escape=False)

    import re

    # <thead> ë°”ë¡œ ë’¤ì— <tr><th>ì²­êµ¬<br>ì„¸ê¸ˆê³„ì‚°ì„œ</th> ... ì‚½ì…
    html_pol = re.sub(
        r'(<thead>\s*<tr>)',
        r'\1<th rowspan="2">ì²­êµ¬<br>ì„¸ê¸ˆê³„ì‚°ì„œ</th>',
        html_pol,
        count=1
    )

    # ['í•©ê³„'] í–‰(7ë²ˆì§¸ ì»¬ëŸ¼) ì—°ì£¼í™©ìƒ‰(#ffe0b2) ë°°ê²½, ['2025 ì´í•©'] ì—´ ì—°íŒŒë‘ìƒ‰(#e3f2fd) ë°°ê²½
    # <tr>ì—ì„œ <th>í•©ê³„</th>ê°€ í¬í•¨ëœ í–‰ ì „ì²´ì˜ <td>ì— ìŠ¤íƒ€ì¼ ì ìš©
    html_pol = re.sub(
        r'(<tr>\s*<th>í•©ê³„</th>)(.*?)(</tr>)',
        lambda m: m.group(1) + re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', m.group(2)) + m.group(3),
        html_pol,
        flags=re.DOTALL
    )
    # <th>í•©ê³„</th>ì—ë„ ë°°ê²½ìƒ‰ ì ìš©
    html_pol = html_pol.replace('<th>í•©ê³„</th>', '<th style="background-color:#ffe0b2;">í•©ê³„</th>')

    # ['2025 ì´í•©'] ì—´(ë§ˆì§€ë§‰ ì»¬ëŸ¼) ì—°íŒŒë‘ìƒ‰(#e3f2fd) ë°°ê²½
    # <thead>ì˜ ë§ˆì§€ë§‰ <th>ì— ìŠ¤íƒ€ì¼ ì ìš©
    html_pol = re.sub(
        r'(<th[^>]*>2025 ì´í•©</th>)',
        r'<th style="background-color:#e3f2fd;">2025 ì´í•©</th>',
        html_pol
    )

    # <tbody>ì˜ ê° í–‰ì—ì„œ ë§ˆì§€ë§‰ <td>ì— ìŠ¤íƒ€ì¼ ì ìš© (2025 ì´í•© ë°ì´í„° ì…€)
    html_pol = re.sub(
        r'(<tr>.*?)(<td[^>]*>[^<]*</td>)(\s*</tr>)',
        lambda m: re.sub(
            r'(<td[^>]*>)([^<]*)(</td>)$',
            r'<td style="background-color:#e3f2fd;">\2</td>',
            m.group(0)
        ),
        html_pol,
        flags=re.DOTALL
    )

    # <tbody>ì˜ ê° í–‰ì—ì„œ '2025 ì´í•©'ì— í•´ë‹¹í•˜ëŠ” <td>ì—ë„ ë°°ê²½ìƒ‰ ì ìš© (í—¤ë”ë¿ ì•„ë‹ˆë¼ ë°ì´í„°ê¹Œì§€)
    # ìœ„ì—ì„œ ì´ë¯¸ ë§ˆì§€ë§‰ <td>ì— ì¹ í–ˆìœ¼ë‚˜, í˜¹ì‹œ ìˆœì„œê°€ ë°”ë€Œê±°ë‚˜ ì»¬ëŸ¼ ì¶”ê°€ì‹œ ëŒ€ë¹„í•´ '2025 ì´í•©' í…ìŠ¤íŠ¸ê°€ ë“¤ì–´ê°„ <td>ë„ ì¹ í•¨
    html_pol = re.sub(
        r'(<td[^>]*>)([^<]*2025 ì´í•©[^<]*)(</td>)',
        r'<td style="background-color:#e3f2fd;">\2</td>',
        html_pol
    )

    # <tbody>ì˜ ê° í–‰ì—ì„œ 'í•©ê³„' ì»¬ëŸ¼(ì¦‰, 7ë²ˆì§¸ ì»¬ëŸ¼)ì— í•´ë‹¹í•˜ëŠ” <td>ì—ë„ ë°°ê²½ìƒ‰ ì ìš©
    # 'í•©ê³„'ëŠ” í—¤ë”ì—ë§Œ ì¹ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë°ì´í„° ì…€ì—ë„ ì¹ í•´ì•¼ í•˜ë¯€ë¡œ, 7ë²ˆì§¸ <td>ì— ì¹ í•¨
    def color_sum_column(match):
        row = match.group(0)
        # 7ë²ˆì§¸ <td>ë¥¼ ì°¾ì•„ì„œ ìƒ‰ì¹ 
        tds = re.findall(r'(<td[^>]*>[^<]*</td>)', row)
        if len(tds) >= 7:
            tds[6] = re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', tds[6])
            # ë‹¤ì‹œ ì¡°ë¦½
            row_new = row
            for i, td in enumerate(tds):
                # ì²« ë²ˆì§¸ ë“±ì¥í•˜ëŠ” <td>ë§Œ ìˆœì„œëŒ€ë¡œ êµì²´
                row_new = re.sub(r'(<td[^>]*>[^<]*</td>)', lambda m: td if m.start() == 0 else m.group(0), row_new, count=1)
            return row_new
        else:
            return row
    html_pol = re.sub(r'<tr>(.*?)</tr>', color_sum_column, html_pol, flags=re.DOTALL)

    st.markdown(html_pol, unsafe_allow_html=True)

    # --- ë‘ ë²ˆì§¸ í‘œ: 7ì›” í˜„í™© (ë°˜ìª½ ì˜ì—­) ---
    second_data = {
        'ì „ì›” ì´ì›”ìˆ˜ëŸ‰': [86,54,32,0],
        'ë‹¹ì¼': [0,0,0,0],
        'ë‹¹ì›”_ëˆ„ê³„': [0,0,0,0]
    }
    second_df = pd.DataFrame(second_data, index=row_idx)
    second_html = second_df.to_html(classes='custom_table', border=0, escape=False)

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("7ì›” í˜„í™©")
        st.markdown(second_html, unsafe_allow_html=True)

    with col2:
        st.subheader("ë¯¸ì ‘ìˆ˜/ë³´ì™„/ì·¨ì†Œ í˜„í™©")
        third_cols = pd.MultiIndex.from_tuples([
            ('ë¯¸ì ‘ìˆ˜ëŸ‰','ì„œë¥˜ë¯¸ë¹„'), ('ë¯¸ì ‘ìˆ˜ëŸ‰','ëŒ€ê¸°ìš”ì²­'),
            ('ë³´ì™„ ì”ì—¬ ìˆ˜ëŸ‰','ì„œë¥˜ë¯¸ë¹„'), ('ë³´ì™„ ì”ì—¬ ìˆ˜ëŸ‰','ë¯¸ì²˜ë¦¬'),
            ('ì·¨ì†Œ','ë‹¨ìˆœì·¨ì†Œ'), ('ì·¨ì†Œ','ë‚´ë¶€ì§€ì›ì „í™˜')
        ])
        third_df = pd.DataFrame([
            [2,2,4,0,6,3],
            [4,4,4,4,9,9]
        ], index=['ë‹¹ì¼','ëˆ„ê³„'], columns=third_cols)
        third_html = third_df.to_html(classes='custom_table', border=0, escape=False)
        st.markdown(third_html, unsafe_allow_html=True)

    st.stop()

# --- ì§€ë„ ë·°ì–´ ---
if viewer_option == 'ì§€ë„(í…ŒìŠ¤íŠ¸)':
    # --- ëŒ€í•œë¯¼êµ­ ì§€ë„ ì‹œê°í™” ---
    st.markdown("---")
    st.header("ğŸ—ºï¸ ëŒ€í•œë¯¼êµ­ ì§€ë„ ì‹œê°í™”")

    # í–‰ì •êµ¬ì—­ ì¢Œí‘œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    if not df_admin_coords.empty:
        st.success("í–‰ì •êµ¬ì—­ë³„ ìœ„ê²½ë„ ì¢Œí‘œ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        try:
            # ì‹œë„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            sido_list = ["ì „ì²´"] + sorted(df_admin_coords['ì‹œë„'].unique().tolist())
            
            # ì§€ì—­ ì„ íƒ UI
            col1, col2, col3 = st.columns([1, 1, 1])
            with col1:
                selected_sido = st.selectbox("ì‹œë„ ì„ íƒ", sido_list)
            
            with col2:
                # ì„ íƒëœ ì‹œë„ì— ë”°ë¥¸ ì‹œêµ°êµ¬ ëª©ë¡
                if selected_sido and selected_sido != "ì „ì²´":
                    # ì‹œêµ°êµ¬ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì •ë ¬
                    sigungu_data = df_admin_coords[df_admin_coords['ì‹œë„'] == selected_sido]['ì‹œêµ°êµ¬'].unique()
                    sigungu_list = ["ì „ì²´"] + sorted([str(x) for x in sigungu_data if pd.notna(x)])
                else:
                    sigungu_list = ["ì „ì²´"]
                selected_sigungu = st.selectbox("ì‹œêµ°êµ¬ ì„ íƒ", sigungu_list)
            
            # --- ì§€ë„ í™•ëŒ€/ì¶•ì†Œ ë¡œì§ ì¶”ê°€ ---
            zoom_level = 6  # ê¸°ë³¸ ì „êµ­ ë·°
            if selected_sido != "ì „ì²´":
                zoom_level = 8  # ì‹œë„ ì„ íƒ ì‹œ í™•ëŒ€
            if selected_sigungu != "ì „ì²´" and selected_sigungu:
                zoom_level = 11 # ì‹œêµ°êµ¬ ì„ íƒ ì‹œ ë” í™•ëŒ€

            # í–‰ì •êµ¬ì—­ ì¢Œí‘œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì§€ë„ ë°ì´í„° ìƒì„± (sample_value ì œê±°)
            map_data = create_admin_map_data(df_admin_coords, selected_sido, selected_sigungu)
            
            # ì§€ë„ í‘œì‹œ (ë™ì  zoom_level ì ìš©)
            st.subheader("í–‰ì •êµ¬ì—­ë³„ ë°ì´í„° ì§€ë„")
            if map_data and map_data['lat']:
                # size ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                if 'size' in map_data:
                    # size ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ë„ í‘œì‹œ
                    map_df = pd.DataFrame({
                        'lat': map_data['lat'],
                        'lon': map_data['lon'],
                        'size': map_data['size']
                    })
                    st.map(data=map_df, zoom=zoom_level+2)
                else:
                    # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì§€ë„ í‘œì‹œ
                    st.map(data=map_data, zoom=zoom_level+2)
            else:
                st.warning("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ì–´ ì§€ë„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì„ íƒëœ ì§€ì—­ ì •ë³´ í‘œì‹œ
            if selected_sido != "ì „ì²´":
                st.info(f"**ì„ íƒëœ ì‹œë„:** {selected_sido}")
                if selected_sigungu != "ì „ì²´":
                    st.info(f"**ì„ íƒëœ ì‹œêµ°êµ¬:** {selected_sigungu}")
                st.info(f"**ìƒì„±ëœ í¬ì¸íŠ¸ ìˆ˜:** {len(map_data['lat'])}")
                
                # size ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                if 'size' in map_data and map_data['size']:
                    avg_size = sum(map_data['size']) / len(map_data['size'])
                    min_size = min(map_data['size'])
                    max_size = max(map_data['size'])
                    st.info(f"**ì› í¬ê¸° ë°ì´í„°:** í‰ê·  {avg_size:.1f}, ìµœì†Œ {min_size}, ìµœëŒ€ {max_size}")
            
            # í•„í„°ë§ëœ ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
            st.subheader("ğŸ“Š ì„ íƒëœ ì§€ì—­ ë°ì´í„° í˜„í™©")
            filtered_data = df_admin_coords.copy()
            if selected_sido != "ì „ì²´":
                filtered_data = filtered_data[filtered_data['ì‹œë„'] == selected_sido]
            if selected_sigungu != "ì „ì²´":
                filtered_data = filtered_data[filtered_data['ì‹œêµ°êµ¬'].astype(str) == selected_sigungu]
            
            if not filtered_data.empty:
                # size ë°ì´í„° ì¶”ê°€
                display_data = filtered_data.copy()
                size_list = []
                for i in range(len(display_data)):
                    sigungu_name = str(display_data.iloc[i]['ì‹œêµ°êµ¬'])
                    np.random.seed(hash(sigungu_name) % 2**32)
                    random_value = np.random.randint(10, 1001)
                    size_list.append(random_value)
                display_data['ì›_í¬ê¸°_ë°ì´í„°'] = size_list
                
                st.dataframe(display_data, use_container_width=True)
                st.info(f"ì´ {len(filtered_data)}ê°œì˜ í–‰ì •êµ¬ì—­ì´ í‘œì‹œë©ë‹ˆë‹¤.")
            else:
                st.warning("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ì§€ë„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.write("**ì „ì²´ í–‰ì •êµ¬ì—­ ë°ì´í„°:**")
            st.dataframe(df_admin_coords.head(10))

    else:
        st.warning("âš ï¸ í–‰ì •êµ¬ì—­ë³„ ìœ„ê²½ë„ ì¢Œí‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.info("'ì „ì²˜ë¦¬.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ 'í–‰ì •êµ¬ì—­ë³„_ìœ„ê²½ë„_ì¢Œí‘œ.xlsx' íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        
        # ê¸°ì¡´ ê°„ë‹¨í•œ ì§€ë„ ë°ì´í„°ë¡œ ëŒ€ì²´
        st.subheader("ğŸ“ ê¸°ë³¸ ì§€ë„ (ì„ì‹œ)")
        korea_map_df = create_korea_map_data()
        
        if not korea_map_df.empty:
            try:
                # ì§€ì—­ ì„ íƒ UI
                col1, col2 = st.columns([2, 1])
                with col1:
                    selected_region = st.selectbox("ì§€ì—­ ì„ íƒ", ["ì „ì²´"] + korea_map_df['region'].tolist())
                
                # st.mapì„ ìœ„í•œ ê°„ë‹¨í•œ ë°ì´í„° ìƒì„± (sample_value ì œê±°)
                map_data = create_simple_map_data(selected_region)
                
                # ì§€ë„ í‘œì‹œ
                st.map(data=map_data, zoom=6)
                
                # ì„ íƒëœ ì§€ì—­ ì •ë³´ í‘œì‹œ
                if selected_region != "ì „ì²´":
                    selected_data = korea_map_df[korea_map_df['region'] == selected_region]
                    st.info(f"**ì„ íƒëœ ì§€ì—­:** {selected_region}")
                    st.info(f"**ìœ„ë„:** {selected_data['lat'].values[0]:.4f}")
                    st.info(f"**ê²½ë„:** {selected_data['lon'].values[0]:.4f}")
                    st.info(f"**ìƒì„±ëœ í¬ì¸íŠ¸ ìˆ˜:** {len(map_data['lat'])}")
                
                # ì „ì²´ ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
                st.subheader("ğŸ“Š ì§€ì—­ë³„ ë°ì´í„° í˜„í™©")
                st.dataframe(korea_map_df, use_container_width=True)

            except Exception as e:
                st.error(f"ì§€ë„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.write("**ì „ì²´ ì§€ë„ ë°ì´í„°:**")
                st.dataframe(korea_map_df)
        else:
            st.warning("ì§€ë„ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

# --- ì§€ìì²´ë³„ ì •ë¦¬ ---
if viewer_option == 'ì§€ìì²´ë³„ ì •ë¦¬':
    st.header("ì§€ìì²´ë³„ í˜„í™© ì •ë¦¬")
    if df_master.empty or 'ì§€ì—­' not in df_master.columns:
        st.warning("ì§€ìì²´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        region_list = df_master['ì§€ì—­'].dropna().unique().tolist()
        selected_region = st.selectbox("ì§€ì—­ ì„ íƒ", region_list)
        columns_to_show = [
            'í˜„í™©_ì¼ë°˜', 'í˜„í™©_ìš°ì„ ',
            'Model 3 RWD_ê¸°ë³¸', 'Model 3 RWD(2024)_ê¸°ë³¸',
            'Model 3 LongRange_ê¸°ë³¸', 'Model 3 Performance_ê¸°ë³¸',
            'Model Y New RWD_ê¸°ë³¸', 'Model Y New LongRange_ê¸°ë³¸'
        ]
        filtered = df_master[df_master['ì§€ì—­'] == selected_region]
        display_columns = [col.replace('_ê¸°ë³¸', '') for col in columns_to_show]
        display_df = filtered[columns_to_show].copy()
        display_df.columns = display_columns
        st.dataframe(display_df, use_container_width=True)




