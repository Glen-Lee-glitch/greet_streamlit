import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
import altair as alt
import pickle
import json
import re
import plotly.express as px
from shapely.geometry import shape
from shapely.ops import unary_union

import sys
from datetime import datetime, timedelta, date
import pytz

# --- í˜ì´ì§€ ì„¤ì • ë° ê¸°ë³¸ ìŠ¤íƒ€ì¼ ---
st.set_page_config(layout="wide")
st.markdown("""
<style>
    /* ê¸°ë³¸ í…Œì´ë¸” ìŠ¤íƒ€ì¼ */
    .custom_table {
        width: 100%;
        border-collapse: collapse;
        font-size: 0.9rem;
    }
    .custom_table th, .custom_table td {
        border: 1px solid #e0e0e0;
        padding: 8px;
        text-align: center;
    }
    .custom_table th {
        background-color: #f7f7f9;
        font-weight: bold;
    }
    .custom_table tr:nth-child(even) {
        background-color: #fafafa;
    }
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    .css-1d391kg {
        padding-top: 3rem;
    }
    /* ì¸ì‡„ ë˜ëŠ” PDF ìƒì„± ì‹œ ë¶ˆí•„ìš”í•œ UI ìˆ¨ê¸°ê¸° */
    @media print {
        /* ì‚¬ì´ë“œë°”ì™€ ëª¨ë“  no-print í´ë˜ìŠ¤ ìš”ì†Œ ìˆ¨ê¸°ê¸° */
        div[data-testid="stSidebar"], .no-print {
            display: none !important;
        }
        /* ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ íŒ¨ë”© ì¡°ì ˆ */
        .main .block-container {
            padding: 1rem !important;
        }
    }
</style>
""", unsafe_allow_html=True)

# --- ë°ì´í„° ë° ë©”ëª¨ ë¡œë”© í•¨ìˆ˜ ---
@st.cache_data(ttl=3600)
def load_data():
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open("preprocessed_data.pkl", "rb") as f:
            return pickle.load(f)
    except FileNotFoundError:
        st.error("ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼(preprocessed_data.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ë¨¼ì € 'ì „ì²˜ë¦¬.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")

def get_base_city_name(sggnm_str):
    """
    ì‹œêµ°êµ¬ëª…ì—ì„œ ê¸°ë³¸ ì‹œ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆ: 'ìˆ˜ì›ì‹œíŒ”ë‹¬êµ¬' -> 'ìˆ˜ì›ì‹œ', 'ì²­ì£¼ì‹œí¥ë•êµ¬' -> 'ì²­ì£¼ì‹œ'
    """
    if pd.isna(sggnm_str): return None
    sggnm_str = str(sggnm_str)
    match = re.search(r'(.+?ì‹œ)', sggnm_str)
    if match:
        return match.group(1)
    return sggnm_str

@st.cache_data
def load_and_process_data(region_counts, geojson_path):
    """
    df_6 ë°ì´í„°ë¥¼ GeoJSONê³¼ ë§¤ì¹­í•˜ê³ , 3ê°€ì§€ ì¼€ì´ìŠ¤ì— ë§ì¶°
    GeoJSONì˜ ê²½ê³„ë¥¼ ë™ì ìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ìµœì¢… ì§€ë„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # 1. GeoJSON íŒŒì¼ ë¡œë“œ
        with open(geojson_path, 'r', encoding='utf-8') as f:
            geojson_data = json.load(f)

        # --- 2. GeoJSON ê·¸ë£¹í™” (í•µì‹¬ ë¡œì§) ---
        geometries_to_merge = {}
        
        sido_special_list = [
            'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 
            'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
        ]

        for feature in geojson_data['features']:
            properties = feature['properties']
            sido = properties.get('sidonm', '')
            sgg = properties.get('sggnm', '')
            if not (sido and sgg and feature.get('geometry')):
                continue

            geom = shape(feature['geometry'])

            # Case 1: ì„œìš¸íŠ¹ë³„ì‹œ, ê´‘ì—­ì‹œ ë“±ì€ 'ì‹œë„' ì´ë¦„ìœ¼ë¡œ ê·¸ë£¹í™”
            if sido in sido_special_list:
                key = sido
            # Case 2 & 3: ê·¸ ì™¸ ì§€ì—­ì€ 'ì‹œë„ ì‹œêµ°êµ¬' ì´ë¦„ìœ¼ë¡œ ê·¸ë£¹í™”
            else:
                # 'ìˆ˜ì›ì‹œì˜í†µêµ¬' -> 'ìˆ˜ì›ì‹œ'ë¡œ ë³€í™˜
                base_sgg = get_base_city_name(sgg)
                key = f"{sido} {base_sgg}"
            
            if key not in geometries_to_merge:
                geometries_to_merge[key] = []
            geometries_to_merge[key].append(geom)

        # --- 3. ì§€ì˜¤ë©”íŠ¸ë¦¬ ë³‘í•© ---
        base_map_geoms = {}
        for key, geoms in geometries_to_merge.items():
            if geoms:
                try:
                    base_map_geoms[key] = unary_union(geoms)
                except Exception:
                    continue
        
        # --- 4. df_6 ë°ì´í„°ë¥¼ ë³‘í•©ëœ ì§€ë„ì— ë§¤í•‘ ---
        final_counts = {key: 0 for key in base_map_geoms.keys()}
        unmatched_regions = set(region_counts.keys())

        for region, count in region_counts.items():
            region_str = str(region).strip()
            matched = False
            
            # Case 1: 'ì„œìš¸íŠ¹ë³„ì‹œ'ì™€ ê°™ì€ ì‹œë„ëª… ì§ì ‘ ë§¤ì¹­
            if region_str in final_counts:
                final_counts[region_str] += count
                unmatched_regions.discard(region_str)
                matched = True
            
            # Case 2 & 3: 'ìˆ˜ì›ì‹œ' -> 'ê²½ê¸°ë„ ìˆ˜ì›ì‹œ'ì™€ ê°™ì€ ì‹œêµ°êµ¬ëª… ë§¤ì¹­
            if not matched:
                # get_base_city_nameì„ df_6ì˜ ì§€ì—­ëª…ì—ë„ ì ìš©í•˜ì—¬ í‚¤ ì¼ê´€ì„± í™•ë³´
                base_region = get_base_city_name(region_str)
                for key in final_counts.keys():
                    if key.endswith(" " + base_region):
                        final_counts[key] += count
                        unmatched_regions.discard(region_str)
                        matched = True
                        # í•˜ë‚˜ì˜ ì‹œêµ°êµ¬ëŠ” í•˜ë‚˜ì˜ ì‹œë„ì—ë§Œ ì†í•˜ë¯€ë¡œ break
                        break
        
        # --- 5. ìµœì¢… GeoJSON ìƒì„± ---
        merged_features = []
        for region_key, geom in base_map_geoms.items():
            merged_feature = {
                'type': 'Feature',
                'geometry': geom.__geo_interface__,
                'properties': {
                    'sggnm': region_key, # ë³‘í•©ëœ ì§€ì—­ì˜ ì´ë¦„ì„ keyë¡œ ì‚¬ìš©
                    'value': final_counts.get(region_key, 0)
                }
            }
            merged_features.append(merged_feature)

        merged_geojson = {'type': 'FeatureCollection', 'features': merged_features}
        
        unmatched_df = pd.DataFrame({
            'ì§€ì—­êµ¬ë¶„': list(unmatched_regions),
            'ì¹´ìš´íŠ¸': [region_counts.get(r, 0) for r in unmatched_regions]
        })

        return merged_geojson, unmatched_df

    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, pd.DataFrame()

def load_memo():
    """ì €ì¥ëœ ë©”ëª¨ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open("memo.txt", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

def create_korea_map_data():
    """ê°„ë‹¨í•œ í•œêµ­ ì§€ë„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # í•œêµ­ì˜ ì£¼ìš” ì§€ì—­ ë°ì´í„° (ê°„ì†Œí™”ëœ ë²„ì „)
    import numpy as np
    korea_data = {
        'region': [
            'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ',
            'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›ë„', 'ì¶©ì²­ë¶ë„', 'ì¶©ì²­ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì „ë¼ë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
        ],
        'lat': [
            37.5665, 35.1796, 35.8714, 37.4563, 35.1595, 36.3504, 35.5384,
            36.4870, 37.4138, 37.8228, 36.8000, 36.5184, 35.7175, 34.8679, 36.4919, 35.4606, 33.4996
        ],
        'lon': [
            126.9780, 129.0756, 128.6014, 126.7052, 126.8526, 127.3845, 129.3114,
            127.2822, 127.5183, 128.1555, 127.7000, 126.8000, 127.1530, 126.9910, 128.8889, 128.2132, 126.5312
        ],
        'value': np.random.randint(10, 1000, size=17).tolist()  # 10~999 ì‚¬ì´ ëœë¤ê°’
    }
    return pd.DataFrame(korea_data)

# --- ë°ì´í„° ë¡œë”© ---
data = load_data()
df = data["df"]
df_1 = data["df_1"]
df_2 = data["df_2"]
df_3 = data["df_3"]
df_4 = data["df_4"]
df_5 = data["df_5"]
df_sales = data["df_sales"]
df_fail_q3 = data["df_fail_q3"]
df_2_fail_q3 = data["df_2_fail_q3"]
update_time_str = data["update_time_str"]
df_master = data.get("df_master", pd.DataFrame())  # ì§€ìì²´ ì •ë¦¬ master.xlsx ë°ì´í„°
df_6 = data.get("df_6", pd.DataFrame())  # ì§€ì—­êµ¬ë¶„ ë°ì´í„°
df_tesla_ev = data["df_tesla_ev"]
preprocessed_map_geojson = data["preprocessed_map_geojson"]

# --- ì‹œê°„ëŒ€ ì„¤ì • ---
KST = pytz.timezone('Asia/Seoul')
today_kst = datetime.now(KST).date()

# --- ì‚¬ì´ë“œë°”: ì¡°íšŒ ì˜µì…˜ ì„¤ì • ---
with st.sidebar:
    st.header("ğŸ‘ï¸ ë·°ì–´ ì˜µì…˜")
    viewer_option = st.radio("ë·°ì–´ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.", ('ë‚´ë¶€', 'í…ŒìŠ¬ë¼', 'í´ìŠ¤íƒ€', 'ì§€ë„(í…ŒìŠ¤íŠ¸)', 'ë¶„ì„'), key="viewer_option")
    st.markdown("---")
    st.header("ğŸ“Š ì¡°íšŒ ì˜µì…˜")
    view_option = st.radio(
        "ì¡°íšŒ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.",
        ('ê¸ˆì¼', 'íŠ¹ì •ì¼ ì¡°íšŒ', 'ê¸°ê°„ë³„ ì¡°íšŒ', 'ë¶„ê¸°ë³„ ì¡°íšŒ', 'ì›”ë³„ ì¡°íšŒ'),
        key="view_option"
    )

    start_date, end_date = None, None
    
    lst_1 = ['ë‚´ë¶€', 'í…ŒìŠ¬ë¼', 'í´ìŠ¤íƒ€']

    if viewer_option in lst_1:

        if view_option == 'ê¸ˆì¼' :
            title = f"ê¸ˆì¼ ë¦¬í¬íŠ¸ - {today_kst.strftime('%Yë…„ %mì›” %dì¼')}"
        else:
            title = f"{view_option} ë¦¬í¬íŠ¸"

        if view_option == 'ê¸ˆì¼':
            start_date = end_date = today_kst
        elif view_option == 'íŠ¹ì •ì¼ ì¡°íšŒ':
            # 6ì›” 24ì¼ë¶€í„°ë§Œ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡ ìµœì†Œ ë‚ ì§œ ì œí•œ ì„¤ì •
            earliest_date = datetime(today_kst.year, 6, 24).date()
            # ë§Œì•½ ì˜¤ëŠ˜ì´ 6ì›” 24ì¼ ì´ì „ì´ë¼ë©´ ì „ë…„ë„ 6ì›” 24ì¼ì„ ìµœì†Œê°’ìœ¼ë¡œ ì‚¬ìš©
            if today_kst < earliest_date:
                earliest_date = datetime(today_kst.year - 1, 6, 24).date()
            selected_date = st.date_input(
                'ë‚ ì§œ ì„ íƒ',
                value=max(today_kst, earliest_date),
                min_value=earliest_date,
                max_value=today_kst
            )
            start_date = end_date = selected_date
            title = f"{selected_date.strftime('%Y-%m-%d')} ë¦¬í¬íŠ¸"
        elif view_option == 'ê¸°ê°„ë³„ ì¡°íšŒ':
            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input('ì‹œì‘ì¼', value=today_kst.replace(day=1))
            with col2:
                end_date = st.date_input('ì¢…ë£Œì¼', value=today_kst)
            if start_date > end_date:
                st.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            title = f"{start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ë¦¬í¬íŠ¸"
        elif view_option == 'ë¶„ê¸°ë³„ ì¡°íšŒ':
            year = today_kst.year
            quarter = st.selectbox('ë¶„ê¸° ì„ íƒ', [f'{q}ë¶„ê¸°' for q in range(1, 5)], index=(today_kst.month - 1) // 3)
            q_num = int(quarter[0])
            start_month = 3 * q_num - 2
            end_month = 3 * q_num
            start_date = datetime(year, start_month, 1).date()
            end_day = (datetime(year, end_month % 12 + 1, 1) - timedelta(days=1)).day if end_month < 12 else 31
            end_date = datetime(year, end_month, end_day).date()
            title = f"{year}ë…„ {quarter} ë¦¬í¬íŠ¸"
        elif view_option == 'ì›”ë³„ ì¡°íšŒ':
            year = today_kst.year
            month = st.selectbox('ì›” ì„ íƒ', [f'{m}ì›”' for m in range(1, 13)], index=today_kst.month - 1)
            month_num = int(month[:-1])
            start_date = datetime(year, month_num, 1).date()
            end_day = (datetime(year, (month_num % 12) + 1, 1) - timedelta(days=1)).day if month_num < 12 else 31
            end_date = datetime(year, month_num, end_day).date()
            title = f"{year}ë…„ {month} ë¦¬í¬íŠ¸"

        # ì›”ë³„ ìš”ì•½ì€ í•­ìƒ í‘œì‹œ
    show_monthly_summary = True

    st.markdown("---")
    st.header("ğŸ“ ë©”ëª¨")
    memo_content = load_memo()
    new_memo = st.text_area(
        "ë©”ëª¨ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì„¸ìš”.",
        value=memo_content, height=250, key="memo_input"
    )
    if new_memo != memo_content:
        with open("memo.txt", "w", encoding="utf-8") as f:
            f.write(new_memo)
        st.toast("ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---

if viewer_option in lst_1:
    st.title(title)
    st.caption(f"ë§ˆì§€ë§‰ ë°ì´í„° ì—…ë°ì´íŠ¸: {update_time_str}")
    st.markdown("---")
else:
    pass

# --- ê³„ì‚° í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def get_corporate_metrics(df3_raw, df4_raw, start, end):
    """ê¸°ê°„ ë‚´ ë²•ì¸íŒ€ ì‹¤ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # ì§€ì› (íŒŒì´í”„ë¼ì¸, ì§€ì›ì‹ ì²­)
    pipeline, apply = 0, 0
    df3 = df3_raw.copy()
    date_col_3 = 'ì‹ ì²­ ìš”ì²­ì¼'
    if not pd.api.types.is_datetime64_any_dtype(df3[date_col_3]):
        df3[date_col_3] = pd.to_datetime(df3[date_col_3], errors='coerce')
    
    mask3 = (df3[date_col_3].dt.date >= start) & (df3[date_col_3].dt.date <= end)
    df3_period = df3.loc[mask3].dropna(subset=[date_col_3])

    df3_period = df3_period[df3_period['ì ‘ìˆ˜ ì™„ë£Œ'].astype(str).str.strip().isin(['O', 'ã…‡'])]
    if 'ê·¸ë¦¬íŠ¸ ë…¸íŠ¸' in df3_period.columns:
        is_cancelled = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ', na=False)
        is_reapplied = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ í›„ ì¬ì‹ ì²­', na=False)
        df3_period = df3_period[~(is_cancelled & ~is_reapplied)]
    
    b_col_name = df3_period.columns[1]
    df3_period = df3_period[df3_period[b_col_name].notna() & (df3_period[b_col_name] != "")]

    pipeline = int(df3_period['ì‹ ì²­ëŒ€ìˆ˜'].sum())
    mask_bulk_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] > 1
    mask_single_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] == 1
    apply = int(mask_bulk_3.sum() + df3_period.loc[mask_single_3, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())

    # ì§€ê¸‰ (ì§€ê¸‰ì‹ ì²­)
    distribute = 0
    df4 = df4_raw.copy()
    date_col_4 = 'ìš”ì²­ì¼ì'
    if not pd.api.types.is_datetime64_any_dtype(df4[date_col_4]):
        df4[date_col_4] = pd.to_datetime(df4[date_col_4], errors='coerce')

    mask4 = (df4[date_col_4].dt.date >= start) & (df4[date_col_4].dt.date <= end)
    df4_period = df4.loc[mask4].dropna(subset=[date_col_4])
    
    df4_period = df4_period[df4_period['ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€'].astype(str).str.strip() == 'ì™„ë£Œ']
    unique_df4_period = df4_period.drop_duplicates(subset=['ì‹ ì²­ë²ˆí˜¸'])

    mask_bulk_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1
    mask_single_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1
    distribute = int(mask_bulk_4.sum() + unique_df4_period.loc[mask_single_4, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())

    return {'pipeline': pipeline, 'apply': apply, 'distribute': distribute}

# --- ì‹¤ì  ê³„ì‚° ---
corporate_metrics = get_corporate_metrics(df_3, df_4, start_date, end_date)

# --- íŠ¹ì´ì‚¬í•­ ì¶”ì¶œ ---
def extract_special_memo(df_fail_q3, today):
    """
    ì˜¤ëŠ˜ ë‚ ì§œì˜ df_fail_q3ì—ì„œ 'Greet Note'ë³„ ê±´ìˆ˜ë¥¼ ['ë‚´ìš©', 'ê±´ìˆ˜'] í˜•íƒœë¡œ í•œ ì¤„ì”© ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 'ë‚ ì§œ' ì»¬ëŸ¼ì´ datetimeì´ ì•„ë‹ ê²½ìš° ë³€í™˜
    if not pd.api.types.is_datetime64_any_dtype(df_fail_q3['ë‚ ì§œ']):
        df_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_fail_q3['ë‚ ì§œ'], errors='coerce')
    # ì˜¤ëŠ˜ ë‚ ì§œ í•„í„°ë§
    today_fail = df_fail_q3[df_fail_q3['ë‚ ì§œ'].dt.date == today]
    # 'Greet Note' ì»¬ëŸ¼ëª…ì„ ìœ ì—°í•˜ê²Œ ì°¾ê¸° (ê³µë°±Â·ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    lowered_cols = {c.lower().replace(' ', ''): c for c in today_fail.columns}
    # 'greetnote' ë˜ëŠ” 'ë…¸íŠ¸' í‚¤ì›Œë“œ í¬í•¨ ì»¬ëŸ¼ íƒìƒ‰
    note_col = next((orig for key, orig in lowered_cols.items() if 'greetnote' in key or 'ë…¸íŠ¸' in key), None)
    if note_col is None:
        return []
    # value_counts
    note_counts = today_fail[note_col].astype(str).value_counts().reset_index()
    note_counts.columns = ['ë‚´ìš©', 'ê±´ìˆ˜']
    # í•œ ì¤„ì”© ë©”ëª¨ í˜•íƒœë¡œ ë³€í™˜
    memo_lines = [f"{row['ë‚´ìš©']}: {row['ê±´ìˆ˜']}ê±´" for _, row in note_counts.iterrows()]
    return memo_lines

if viewer_option == 'ë‚´ë¶€' or viewer_option == 'í…ŒìŠ¬ë¼':

    # --- ëŒ€ì‹œë³´ë“œ í‘œì‹œ ---
    col1, col2, col3 = st.columns([3.5,2,1.5])

    with col1:
        st.write("### 1. ë¦¬í…Œì¼ ê¸ˆì¼/ì „ì¼ ìš”ì•½")

        selected_date = end_date
        day0 = selected_date
        day1 = (pd.to_datetime(selected_date) - pd.tseries.offsets.BDay(1)).date()

        year = selected_date.year
        q3_start_default = datetime(year, 6, 24).date()
        q3_start_distribute = datetime(year, 7, 1).date()

        # ê¸°ê°„ë³„ ì¡°íšŒì¸ì§€ í™•ì¸
        is_period_view = view_option == 'ê¸°ê°„ë³„ ì¡°íšŒ'

        if is_period_view:
            # ê¸°ê°„ë³„ ì¡°íšŒ: ì„ íƒí•œ ê¸°ê°„ì˜ í•©ê³„ì™€ ëˆ„ì  ì´ê³„ë§Œ í‘œì‹œ
            cnt_period_mail = ((df_5['ë‚ ì§œ'].dt.date >= start_date) & (df_5['ë‚ ì§œ'].dt.date <= end_date)).sum()
            cnt_total_mail = ((df_5['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_5['ë‚ ì§œ'].dt.date <= end_date)).sum()

            cnt_period_apply = int(df_1.loc[(df_1['ë‚ ì§œ'].dt.date >= start_date) & (df_1['ë‚ ì§œ'].dt.date <= end_date), 'ê°œìˆ˜'].sum())
            cnt_total_apply = int(df_1.loc[(df_1['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_1['ë‚ ì§œ'].dt.date <= end_date), 'ê°œìˆ˜'].sum())

            cnt_period_distribute = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= start_date) & (df_2['ë‚ ì§œ'].dt.date <= end_date), 'ë°°ë¶„'].sum())
            cnt_total_distribute = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= end_date), 'ë°°ë¶„'].sum())

            cnt_period_request = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= start_date) & (df_2['ë‚ ì§œ'].dt.date <= end_date), 'ì‹ ì²­'].sum())
            cnt_total_request = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= end_date), 'ì‹ ì²­'].sum())

            # df_fail_q3, df_2_fail_q3 ë‚ ì§œ íƒ€ì… ë³´ì •
            if not pd.api.types.is_datetime64_any_dtype(df_fail_q3['ë‚ ì§œ']):
                df_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_fail_q3['ë‚ ì§œ'], errors='coerce')
            if not pd.api.types.is_datetime64_any_dtype(df_2_fail_q3['ë‚ ì§œ']):
                df_2_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_2_fail_q3['ë‚ ì§œ'], errors='coerce')

            # ë¯¸ì‹ ì²­ê±´ ê³„ì‚° (ê¸°ê°„ë³„)
            cnt_period_fail = int(((df_fail_q3['ë‚ ì§œ'].dt.date >= start_date) & (df_fail_q3['ë‚ ì§œ'].dt.date <= end_date)).sum())
            cnt_total_fail = int(((df_fail_q3['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_fail_q3['ë‚ ì§œ'].dt.date <= end_date)).sum())

            # ì§€ê¸‰ ë¯¸ì‹ ì²­ê±´ ê³„ì‚° (ê¸°ê°„ë³„)
            cnt_period_fail_2 = int(df_2_fail_q3.loc[(df_2_fail_q3['ë‚ ì§œ'].dt.date >= start_date) & (df_2_fail_q3['ë‚ ì§œ'].dt.date <= end_date), 'ë¯¸ì‹ ì²­ê±´'].sum())
            cnt_total_fail_2 = int(df_2_fail_q3.loc[(df_2_fail_q3['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_2_fail_q3['ë‚ ì§œ'].dt.date <= end_date), 'ë¯¸ì‹ ì²­ê±´'].sum())

            table_data = pd.DataFrame({
                ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ë©”ì¼ ê±´ìˆ˜'): [cnt_period_mail, cnt_total_mail],
                ('ì§€ì›', 'ì‹ ì²­', 'ì‹ ì²­ ê±´ìˆ˜'): [cnt_period_apply, cnt_total_apply],
                ('ì§€ì›', 'ì‹ ì²­', 'ë¯¸ì‹ ì²­ê±´'): [cnt_period_fail, cnt_total_fail],
                ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ì§€ê¸‰ ë°°ë¶„ê±´'): [cnt_period_distribute, cnt_total_distribute],
                ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ì§€ê¸‰ì‹ ì²­ ê±´ìˆ˜'): [cnt_period_request, cnt_total_request],
                ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ë¯¸ì‹ ì²­ê±´'): [cnt_period_fail_2, cnt_total_fail_2]
            }, index=['ì„ íƒê¸°ê°„', 'ëˆ„ì  ì´ê³„ (3ë¶„ê¸°)'])

        else:
            # ê¸°ì¡´ ë¡œì§: ê¸ˆì¼/ì „ì¼/ëˆ„ì  í‘œì‹œ
            cnt_today_mail = (df_5['ë‚ ì§œ'].dt.date == day0).sum()
            cnt_yesterday_mail = (df_5['ë‚ ì§œ'].dt.date == day1).sum()
            cnt_total_mail = ((df_5['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_5['ë‚ ì§œ'].dt.date <= day0)).sum()

            cnt_today_apply = int(df_1.loc[df_1['ë‚ ì§œ'].dt.date == day0, 'ê°œìˆ˜'].sum())
            cnt_yesterday_apply = int(df_1.loc[df_1['ë‚ ì§œ'].dt.date == day1, 'ê°œìˆ˜'].sum())
            cnt_total_apply = int(df_1.loc[(df_1['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_1['ë‚ ì§œ'].dt.date <= day0), 'ê°œìˆ˜'].sum())

            cnt_today_distribute = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day0, 'ë°°ë¶„'].sum())
            cnt_yesterday_distribute = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day1, 'ë°°ë¶„'].sum())
            cnt_total_distribute = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= day0), 'ë°°ë¶„'].sum())

            cnt_today_request = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day0, 'ì‹ ì²­'].sum())
            cnt_yesterday_request = int(df_2.loc[df_2['ë‚ ì§œ'].dt.date == day1, 'ì‹ ì²­'].sum())
            cnt_total_request = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= day0), 'ì‹ ì²­'].sum())

            # df_fail_q3, df_2_fail_q3 ë‚ ì§œ íƒ€ì… ë³´ì •
            if not pd.api.types.is_datetime64_any_dtype(df_fail_q3['ë‚ ì§œ']):
                df_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_fail_q3['ë‚ ì§œ'], errors='coerce')
            if not pd.api.types.is_datetime64_any_dtype(df_2_fail_q3['ë‚ ì§œ']):
                df_2_fail_q3['ë‚ ì§œ'] = pd.to_datetime(df_2_fail_q3['ë‚ ì§œ'], errors='coerce')

            # ë¯¸ì‹ ì²­ê±´ ê³„ì‚°
            cnt_yesterday_fail = int((df_fail_q3['ë‚ ì§œ'].dt.date == day1).sum())
            cnt_today_fail = int((df_fail_q3['ë‚ ì§œ'].dt.date == day0).sum())
            cnt_total_fail = int(((df_fail_q3['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_fail_q3['ë‚ ì§œ'].dt.date <= day0)).sum())

            # ì§€ê¸‰ ë¯¸ì‹ ì²­ê±´ ê³„ì‚°
            cnt_yesterday_fail_2 = int(df_2_fail_q3.loc[df_2_fail_q3['ë‚ ì§œ'].dt.date == day1, 'ë¯¸ì‹ ì²­ê±´'].sum())
            cnt_today_fail_2 = int(df_2_fail_q3.loc[df_2_fail_q3['ë‚ ì§œ'].dt.date == day0, 'ë¯¸ì‹ ì²­ê±´'].sum())
            cnt_total_fail_2 = int(df_2_fail_q3.loc[(df_2_fail_q3['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_2_fail_q3['ë‚ ì§œ'].dt.date <= day0), 'ë¯¸ì‹ ì²­ê±´'].sum())

            delta_mail = cnt_today_mail - cnt_yesterday_mail
            delta_apply = cnt_today_apply - cnt_yesterday_apply
            delta_fail = cnt_today_fail - cnt_yesterday_fail
            delta_distribute = cnt_today_distribute - cnt_yesterday_distribute
            delta_request = cnt_today_request - cnt_yesterday_request
            delta_fail_2 = cnt_today_fail_2 - cnt_yesterday_fail_2

            def format_delta(value):
                if value > 0: return f'<span style="color:blue;">+{value}</span>'
                elif value < 0: return f'<span style="color:red;">{value}</span>'
                return str(value)

            table_data = pd.DataFrame({
                ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ë©”ì¼ ê±´ìˆ˜'): [cnt_yesterday_mail, cnt_today_mail, cnt_total_mail],
                ('ì§€ì›', 'ì‹ ì²­', 'ì‹ ì²­ ê±´ìˆ˜'): [cnt_yesterday_apply, cnt_today_apply, cnt_total_apply],
                ('ì§€ì›', 'ì‹ ì²­', 'ë¯¸ì‹ ì²­ê±´'): [cnt_yesterday_fail, cnt_today_fail, cnt_total_fail],
                ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ì§€ê¸‰ ë°°ë¶„ê±´'): [cnt_yesterday_distribute, cnt_today_distribute, cnt_total_distribute],
                ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ì§€ê¸‰ì‹ ì²­ ê±´ìˆ˜'): [cnt_yesterday_request, cnt_today_request, cnt_total_request],
                ('ì§€ê¸‰', 'ì§€ê¸‰ ì²˜ë¦¬', 'ë¯¸ì‹ ì²­ê±´'): [cnt_yesterday_fail_2, cnt_today_fail_2, cnt_total_fail_2]
            }, index=[f'ì „ì¼ ({day1})', f'ê¸ˆì¼ ({day0})', 'ëˆ„ì  ì´ê³„ (3ë¶„ê¸°)'])

            # ë³€ë™(Delta) í–‰ ì¶”ê°€
            table_data.loc['ë³€ë™'] = [
                format_delta(delta_mail),
                format_delta(delta_apply),
                format_delta(delta_fail),
                format_delta(delta_distribute),
                format_delta(delta_request),
                format_delta(delta_fail_2)
            ]

        html_table = table_data.to_html(classes='custom_table', border=0, escape=False)
        st.markdown(html_table, unsafe_allow_html=True)

    with col2:
        st.write("### 2. ë²•ì¸íŒ€ ê¸ˆì¼ ìš”ì•½")
        
        # ìì„¸í•œ ë²•ì¸íŒ€ ì‹¤ì  í…Œì´ë¸” ìƒì„±
        required_cols_df3 = ['ì‹ ì²­ ìš”ì²­ì¼', 'ì ‘ìˆ˜ ì™„ë£Œ', 'ì‹ ì²­ëŒ€ìˆ˜']
        required_cols_df4 = ['ìš”ì²­ì¼ì', 'ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€', 'ì‹ ì²­ë²ˆí˜¸', 'ì ‘ìˆ˜ëŒ€ìˆ˜']

        has_all_cols = all(col in df_3.columns for col in required_cols_df3) and \
                    all(col in df_4.columns for col in required_cols_df4)

        if has_all_cols:
            def process_new(df, end_date):
                df = df.copy()
                date_col = 'ì‹ ì²­ ìš”ì²­ì¼'
                if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                df_cumulative = df[df[date_col].notna() & (df[date_col].dt.date <= end_date)]
                df_cumulative = df_cumulative[df_cumulative['ì ‘ìˆ˜ ì™„ë£Œ'].astype(str).str.strip().isin(['O', 'ã…‡'])]
                if 'ê·¸ë¦¬íŠ¸ ë…¸íŠ¸' in df_cumulative.columns:
                    is_cancelled = df_cumulative['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ', na=False)
                    is_reapplied = df_cumulative['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ í›„ ì¬ì‹ ì²­', na=False)
                    df_cumulative = df_cumulative[~(is_cancelled & ~is_reapplied)]
                b_col_name = df_cumulative.columns[1]
                df_cumulative = df_cumulative[df_cumulative[b_col_name].notna() & (df_cumulative[b_col_name] != "")]
                df_today = df_cumulative[df_cumulative[date_col].dt.date == end_date]

                mask_bulk = df_cumulative['ì‹ ì²­ëŒ€ìˆ˜'] > 1
                mask_single = df_cumulative['ì‹ ì²­ëŒ€ìˆ˜'] == 1

                new_bulk_sum = int(df_cumulative.loc[mask_bulk, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())
                new_single_sum = int(df_cumulative.loc[mask_single, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())
                new_bulk_count = int(mask_bulk.sum())
                today_bulk_count = int((df_today['ì‹ ì²­ëŒ€ìˆ˜'] > 1).sum())
                today_single_count = int((df_today['ì‹ ì²­ëŒ€ìˆ˜'] == 1).sum())

                return new_bulk_sum, new_single_sum, new_bulk_count, today_bulk_count, today_single_count

            def process_give(df, end_date):
                df = df.copy()
                date_col = 'ìš”ì²­ì¼ì'
                if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                df_cumulative = df[df[date_col].notna() & (df[date_col].dt.date <= end_date)]
                df_cumulative = df_cumulative[df_cumulative['ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€'].astype(str).str.strip() == 'ì™„ë£Œ']
                unique_df_cumulative = df_cumulative.drop_duplicates(subset=['ì‹ ì²­ë²ˆí˜¸'])
                df_today = unique_df_cumulative[unique_df_cumulative[date_col].dt.date == end_date]

                mask_bulk = unique_df_cumulative['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1
                mask_single = unique_df_cumulative['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1

                give_bulk_sum = int(unique_df_cumulative.loc[mask_bulk, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())
                give_single_sum = int(unique_df_cumulative.loc[mask_single, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())
                give_bulk_count = int(mask_bulk.sum())
                give_today_bulk_count = int((df_today['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1).sum())
                give_today_single_count = int((df_today['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1).sum())

                return give_bulk_sum, give_single_sum, give_bulk_count, give_today_bulk_count, give_today_single_count

            new_bulk_sum, new_single_sum, new_bulk_count, new_today_bulk_count, new_today_single_count = process_new(df_3, selected_date)
            give_bulk_sum, give_single_sum, give_bulk_count, give_today_bulk_count, give_today_single_count = process_give(df_4, selected_date)

            row_names = ['ë²Œí¬', 'ë‚±ê°œ', 'TTL']
            columns = pd.MultiIndex.from_tuples([
                ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜'), ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼'), ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„'),
                ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜'), ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼'), ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')
            ], names=['', 'ë¶„ë¥˜', 'í•­ëª©'])
            df_total = pd.DataFrame(0, index=row_names, columns=columns)

            # ì§€ì›
            df_total.loc['ë²Œí¬', ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = new_bulk_sum
            df_total.loc['ë‚±ê°œ', ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = new_single_sum
            df_total.loc['TTL', ('ì§€ì›', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = new_bulk_sum + new_single_sum

            df_total.loc['ë²Œí¬', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = new_today_bulk_count
            df_total.loc['ë‚±ê°œ', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = new_today_single_count
            df_total.loc['TTL', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = new_today_bulk_count + new_today_single_count

            df_total.loc['ë²Œí¬', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = new_bulk_count
            df_total.loc['ë‚±ê°œ', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = new_single_sum  # ì›ë³¸ ë¡œì§ ìœ ì§€
            df_total.loc['TTL', ('ì§€ì›', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = new_bulk_count + new_single_sum

            # ì§€ê¸‰
            df_total.loc['ë²Œí¬', ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = give_bulk_sum
            df_total.loc['ë‚±ê°œ', ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = give_single_sum
            df_total.loc['TTL', ('ì§€ê¸‰', 'íŒŒì´í”„ë¼ì¸', 'ëŒ€ìˆ˜')] = give_bulk_sum + give_single_sum

            df_total.loc['ë²Œí¬', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = give_today_bulk_count
            df_total.loc['ë‚±ê°œ', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = give_today_single_count
            df_total.loc['TTL', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ë‹¹ì¼')] = give_today_bulk_count + give_today_single_count

            df_total.loc['ë²Œí¬', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = give_bulk_count
            df_total.loc['ë‚±ê°œ', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = give_single_sum  # ì›ë³¸ ë¡œì§ ìœ ì§€
            df_total.loc['TTL', ('ì§€ê¸‰', 'ì‹ ì²­(ê±´)', 'ëˆ„ê³„')] = give_bulk_count + give_single_sum

            html_table_corp = df_total.to_html(classes='custom_table', border=0)
            st.markdown(html_table_corp, unsafe_allow_html=True)
        else:
            st.warning("ë²•ì¸íŒ€ ì‹¤ì ì„ ê³„ì‚°í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # --- ë©”ëª¨ ì˜ì—­ ---
    with col3:

        def load_memo_file(path:str):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
            except FileNotFoundError:
                return ""

        def save_memo_file(path:str, content:str):
            with open(path, "w", encoding="utf-8") as f:
                f.write(content)

        # íŠ¹ì´ì‚¬í•­ ë©”ëª¨ (ìë™ ì¶”ê°€)
        st.subheader("ë¯¸ì‹ ì²­ê±´")

        # ì˜¤ëŠ˜ ê¸°ì¤€ ìë™ ì¶”ì¶œëœ íŠ¹ì´ì‚¬í•­ ë¼ì¸ë“¤
        auto_special_lines = extract_special_memo(df_fail_q3, selected_date)
        if not auto_special_lines:
            auto_special_lines = ["ì—†ìŒ"]
        auto_special_text = "\n".join(auto_special_lines)

        # memo_special.txt ì— ì €ì¥ëœ ì‚¬ìš©ì ë©”ëª¨
        memo_special_saved = load_memo_file("memo_special.txt")

        # ë””í´íŠ¸ ê°’: ìë™ íŠ¹ì´ì‚¬í•­ + ì €ì¥ëœ ì‚¬ìš©ì ë©”ëª¨(ìˆë‹¤ë©´ ì´ì–´ë¶™ì„)
        default_special = auto_special_text
        if memo_special_saved.strip():
            default_special += ("\n" if default_special else "") + memo_special_saved.strip()

        # CSSë¡œ í°íŠ¸ í¬ê¸° 16px, ì¤„ë°”ê¿ˆ ìœ ì§€, ë°°ê²½ ì—°ì´ˆë¡ìƒ‰(#e0f7fa), í…ìŠ¤íŠ¸ Boldë¡œ í‘œì¶œ
        st.markdown(
            f"<div style='font-size:16px; white-space:pre-wrap; background-color:#e0f7fa; border-radius:8px; padding:10px'><b>{default_special}</b></div>",
            unsafe_allow_html=True,
        )
    
    st.markdown("<hr style='margin-top:1rem;margin-bottom:1rem;'>", unsafe_allow_html=True)

    col4, col5, col6 = st.columns([3.5,2,1.5])

    with col4:
        # ----- ë¦¬í…Œì¼ ì›”ë³„ ìš”ì•½ í—¤ë” ë° ê¸°ê°„ ì„ íƒ -----
        if viewer_option == 'ë‚´ë¶€':
            header_col, sel_col = st.columns([4,2])
            with header_col:
                st.write("##### ë¦¬í…Œì¼ ì›”ë³„ ìš”ì•½")
            with sel_col:
                period_option = st.selectbox(
                    'ê¸°ê°„ ì„ íƒ',
                    ['3Q', '7ì›”', 'ì „ì²´', '1Q', '2Q'] + [f'{m}ì›”' for m in range(1,13)],
                    index=0,
                    key='retail_period')
        else:
            st.write("##### ë¦¬í…Œì¼ ì›”ë³„ ìš”ì•½")
            period_option = 'ì „ì²´'  # í…ŒìŠ¬ë¼ ì˜µì…˜ì¼ ë•ŒëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ 'ì „ì²´' ì‚¬ìš©
        year = today_kst.year
        july_start = datetime(year, 7, 1).date()
        july_end = datetime(year, 7, 31).date()
        august_start = datetime(year, 8, 1).date()
        august_end = datetime(year, 8, 31).date()

        july_mail_count = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_5['ë‚ ì§œ'].dt.date <= july_end)].shape[0]) if july_end >= q3_start_default else 0
        july_apply_count = int(df_1.loc[(df_1['ë‚ ì§œ'].dt.date >= q3_start_default) & (df_1['ë‚ ì§œ'].dt.date <= july_end), 'ê°œìˆ˜'].sum()) if july_end >= q3_start_default else 0
        july_distribute_count = int(df_2.loc[(df_2['ë‚ ì§œ'].dt.date >= q3_start_distribute) & (df_2['ë‚ ì§œ'].dt.date <= july_end), 'ë°°ë¶„'].sum()) if july_end >= q3_start_distribute else 0

        mask_august_5 = (df_5['ë‚ ì§œ'].dt.date >= august_start) & (df_5['ë‚ ì§œ'].dt.date <= august_end)
        mask_august_1 = (df_1['ë‚ ì§œ'].dt.date >= august_start) & (df_1['ë‚ ì§œ'].dt.date <= august_end)
        mask_august_2 = (df_2['ë‚ ì§œ'].dt.date >= august_start) & (df_2['ë‚ ì§œ'].dt.date <= august_end)
        august_mail_count = int(df_5.loc[mask_august_5].shape[0])
        august_apply_count = int(df_1.loc[mask_august_1, 'ê°œìˆ˜'].sum())
        august_distribute_count = int(df_2.loc[mask_august_2, 'ë°°ë¶„'].sum())

        # ----- ê¸°ê°„ë³„ í•„í„°ë§ -----
        def filter_by_period(df):
            if period_option == '3Q' or period_option in ('3ë¶„ê¸°'):
                return df[df['ë¶„ê¸°'] == '3ë¶„ê¸°']
            if period_option == '2Q' or period_option in ('2ë¶„ê¸°'):
                return df[df['ë¶„ê¸°'] == '2ë¶„ê¸°']
            if period_option == '1Q' or period_option in ('1ë¶„ê¸°'):
                return df[df['ë¶„ê¸°'] == '1ë¶„ê¸°']
            if period_option.endswith('ì›”'):
                try:
                    month_num = int(period_option[:-1])
                    return df[df['ë‚ ì§œ'].dt.month == month_num]
                except ValueError:
                    return df
            return df

        # --- ì›”ë³„/ë¶„ê¸°ë³„ ìš”ì•½ ê³„ì‚° ---
        current_year = day0.year
        # ë‚ ì§œ ë³€ìˆ˜ ì •ì˜
        june_23 = datetime(current_year, 6, 23).date()
        june_24 = datetime(current_year, 6, 24).date()
        july_1 = datetime(current_year, 7, 1).date()
        july_31 = datetime(current_year, 7, 31).date()
        august_1 = datetime(current_year, 8, 1).date()
        september_1 = datetime(current_year, 9, 1).date()

        retail_df = pd.DataFrame() # ì´ˆê¸°í™”

        # --- ì´ë¯¸ì§€ í˜•íƒœì˜ ì›”ë³„ ìš”ì•½ í‘œ ìƒì„± ---
        if period_option == 'ì „ì²´':
            # (1Q, 2Q ê³„ì‚° ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
            q1_total_mail = int(df_5[df_5['ë‚ ì§œ'].dt.month.isin([1,2,3])].shape[0])
            q1_total_apply = int(df_1[df_1['ë‚ ì§œ'].dt.month.isin([1,2,3])]['ê°œìˆ˜'].sum())
            q1_total_distribute = int(df_2[df_2['ë‚ ì§œ'].dt.month.isin([1,2,3])]['ë°°ë¶„'].sum())
            q2_total_mail = int(df_5[df_5['ë‚ ì§œ'].dt.month.isin([4,5,6])].shape[0])
            q2_apply_mask = (df_1['ë‚ ì§œ'].dt.month.isin([4,5])) | ((df_1['ë‚ ì§œ'].dt.month == 6) & (df_1['ë‚ ì§œ'].dt.date <= june_23))
            q2_total_apply = int(df_1[q2_apply_mask]['ê°œìˆ˜'].sum())
            q2_total_distribute = int(df_2[df_2['ë‚ ì§œ'].dt.month.isin([4,5,6])]['ë°°ë¶„'].sum())
            
            # --- 3Q ë°ì´í„° ê³„ì‚° (ìˆ˜ì •ëœ ë¡œì§) ---
            july_mail_total = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= june_24) & (df_5['ë‚ ì§œ'].dt.date <= july_31)].shape[0])
            july_apply_total = int(df_1[(df_1['ë‚ ì§œ'].dt.date >= june_24) & (df_1['ë‚ ì§œ'].dt.date <= july_31)]['ê°œìˆ˜'].sum())
            july_distribute_total = int(df_2[(df_2['ë‚ ì§œ'].dt.date >= july_1) & (df_2['ë‚ ì§œ'].dt.date <= july_31)]['ë°°ë¶„'].sum())

            august_cumulative_mail = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= august_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0])
            august_cumulative_apply = int(df_1[(df_1['ë‚ ì§œ'].dt.date >= august_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum())
            august_cumulative_distribute = int(df_2[(df_2['ë‚ ì§œ'].dt.date >= august_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
            
            september_cumulative_mail = int(df_5[(df_5['ë‚ ì§œ'].dt.date >= september_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0])
            september_cumulative_apply = int(df_1[(df_1['ë‚ ì§œ'].dt.date >= september_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum())
            september_cumulative_distribute = int(df_2[(df_2['ë‚ ì§œ'].dt.date >= september_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())

            q3_total_mail = july_mail_total + august_cumulative_mail + september_cumulative_mail
            q3_total_apply = july_apply_total + august_cumulative_apply + september_cumulative_apply
            q3_total_distribute = july_distribute_total + august_cumulative_distribute + september_cumulative_distribute

            q1_target, q2_target, q3_target = 4300, 10000, 10000
            q1_progress = q1_total_mail / q1_target if q1_target > 0 else 0
            q2_progress = q2_total_mail / q2_target if q2_target > 0 else 0
            q3_progress = q3_total_mail / q3_target if q3_target > 0 else 0

            # ê³„ì‚°ì„ ìœ„í•œ í•©ê³„
            total_target = q1_target + q2_target + q3_target
            total_mail = q1_total_mail + q2_total_mail + q3_total_mail
            total_apply = q1_total_apply + q2_total_apply + q3_total_apply
            total_distribute = q1_total_distribute + q2_total_distribute + q3_total_distribute

            retail_df_data = {
                'Q1': [q1_target, q1_total_mail, q1_total_apply, f"{q1_progress:.1%}", '', q1_total_distribute],
                'Q2': [q2_target, q2_total_mail, q2_total_apply, f"{q2_progress:.1%}", '', q2_total_distribute],
                'Q3': [q3_target, q3_total_mail, q3_total_apply, f"{q3_progress:.1%}", 288, q3_total_distribute],
                'ê³„': [total_target, total_mail, total_apply, '', 288, total_distribute]
            }
            retail_index = ['íƒ€ê²Ÿ', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì§„ì²™ë¥ ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­']
            retail_df = pd.DataFrame(retail_df_data, index=retail_index)

        elif period_option == '1Q' or period_option == '1ë¶„ê¸°':
            # Q1 ë°ì´í„° ê³„ì‚° (1, 2, 3ì›”)
            q1_monthly_data = {}
            for month in [1, 2, 3]:
                month_mail = int(df_5[df_5['ë‚ ì§œ'].dt.month == month].shape[0])
                month_apply = int(df_1[df_1['ë‚ ì§œ'].dt.month == month]['ê°œìˆ˜'].sum())
                month_distribute = int(df_2[df_2['ë‚ ì§œ'].dt.month == month]['ë°°ë¶„'].sum())
                q1_monthly_data[f'{month}'] = [month_mail, month_apply, month_distribute]
            
            # Q1 í•©ê³„ ê³„ì‚°
            q1_total_mail = sum(q1_monthly_data[f'{m}'][0] for m in [1, 2, 3])
            q1_total_apply = sum(q1_monthly_data[f'{m}'][1] for m in [1, 2, 3])
            q1_total_distribute = sum(q1_monthly_data[f'{m}'][2] for m in [1, 2, 3])
            
            # íƒ€ê²Ÿ ì„¤ì •
            q1_target = 4300
            
            # ì§„ì²™ë¥  ê³„ì‚°
            q1_progress_rate = q1_total_mail / q1_target if q1_target > 0 else 0
            
            retail_df_data = {
                '1': ['', q1_monthly_data['1'][0], q1_monthly_data['1'][1], '', q1_monthly_data['1'][2]],
                '2': ['', q1_monthly_data['2'][0], q1_monthly_data['2'][1], '', q1_monthly_data['2'][2]],
                '3': ['', q1_monthly_data['3'][0], q1_monthly_data['3'][1], '', q1_monthly_data['3'][2]],
                'ê³„': ['', q1_total_mail, q1_total_apply, '', q1_total_distribute]
            }
            retail_index = ['íƒ€ê²Ÿ (ì§„ì²™ë¥ )', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­']
            retail_df = pd.DataFrame(retail_df_data, index=retail_index)
        elif period_option == '2Q' or period_option == '2ë¶„ê¸°':
            # Q2 ë°ì´í„° ê³„ì‚° (4, 5, 6ì›”) - 6ì›”ì€ 6ì›” 23ì¼ê¹Œì§€
            q2_monthly_data = {}
            
            # 6ì›” 23ì¼ ë‚ ì§œ ê°ì²´ ìƒì„± (í˜„ì¬ ì—°ë„ ê¸°ì¤€)
            current_year = datetime.now().year
            june_23 = datetime(current_year, 6, 23).date()
            
            for month in [4, 5, 6]:
                month_mail = int(df_5[df_5['ë‚ ì§œ'].dt.month == month].shape[0])
                
                # 6ì›”ì˜ ê²½ìš° 6ì›” 23ì¼ê¹Œì§€ì˜ ë°ì´í„°ë§Œ í¬í•¨
                if month == 6:
                    month_apply = int(df_1[
                        (df_1['ë‚ ì§œ'].dt.month == 6) & 
                        (df_1['ë‚ ì§œ'].dt.date <= june_23)
                    ]['ê°œìˆ˜'].sum())
                else:
                    month_apply = int(df_1[df_1['ë‚ ì§œ'].dt.month == month]['ê°œìˆ˜'].sum())
                
                month_distribute = int(df_2[df_2['ë‚ ì§œ'].dt.month == month]['ë°°ë¶„'].sum())
                q2_monthly_data[f'{month}'] = [month_mail, month_apply, month_distribute]
            
            # Q2 í•©ê³„ ê³„ì‚°
            q2_total_mail = sum(q2_monthly_data[f'{m}'][0] for m in [4, 5, 6])
            q2_total_apply = sum(q2_monthly_data[f'{m}'][1] for m in [4, 5, 6])
            q2_total_distribute = sum(q2_monthly_data[f'{m}'][2] for m in [4, 5, 6])
            
            # íƒ€ê²Ÿ ì„¤ì •
            q2_target = 10000
            
            # ì§„ì²™ë¥  ê³„ì‚°
            q2_progress_rate = q2_total_mail / q2_target if q2_target > 0 else 0
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            retail_df_data = {
                '4': ['', q2_monthly_data['4'][0], q2_monthly_data['4'][1], '', q2_monthly_data['4'][2]],
                '5': ['', q2_monthly_data['5'][0], q2_monthly_data['5'][1], '', q2_monthly_data['5'][2]],
                '6': ['', q2_monthly_data['6'][0], q2_monthly_data['6'][1], '', q2_monthly_data['6'][2]],
                'ê³„': ['', q2_total_mail, q2_total_apply, '', q2_total_distribute]
            }
            retail_index = ['íƒ€ê²Ÿ (ì§„ì²™ë¥ )', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­']
            retail_df = pd.DataFrame(retail_df_data, index=retail_index)
        elif period_option in ('3Q', '3ë¶„ê¸°'):
            # --- 3Q ì›”ë³„ ë°ì´í„° ê³„ì‚° (ìˆ˜ì •ëœ ë¡œì§) ---
            q3_monthly_data = {}
            
            # 7ì›” ë°ì´í„° (ì „ì²´ ì›”)
            q3_monthly_data['7'] = [
                int(df_5[(df_5['ë‚ ì§œ'].dt.date >= june_24) & (df_5['ë‚ ì§œ'].dt.date <= july_31)].shape[0]),
                int(df_1[(df_1['ë‚ ì§œ'].dt.date >= june_24) & (df_1['ë‚ ì§œ'].dt.date <= july_31)]['ê°œìˆ˜'].sum()),
                int(df_2[(df_2['ë‚ ì§œ'].dt.date >= july_1) & (df_2['ë‚ ì§œ'].dt.date <= july_31)]['ë°°ë¶„'].sum())
            ]
            # 8ì›” ë°ì´í„° (ì›”ì´ˆ ~ í˜„ì¬)
            q3_monthly_data['8'] = [
                int(df_5[(df_5['ë‚ ì§œ'].dt.date >= august_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0]),
                int(df_1[(df_1['ë‚ ì§œ'].dt.date >= august_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum()),
                int(df_2[(df_2['ë‚ ì§œ'].dt.date >= august_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
            ]
            # 9ì›” ë°ì´í„° (ì›”ì´ˆ ~ í˜„ì¬)
            q3_monthly_data['9'] = [
                int(df_5[(df_5['ë‚ ì§œ'].dt.date >= september_1) & (df_5['ë‚ ì§œ'].dt.date <= day0)].shape[0]),
                int(df_1[(df_1['ë‚ ì§œ'].dt.date >= september_1) & (df_1['ë‚ ì§œ'].dt.date <= day0)]['ê°œìˆ˜'].sum()),
                int(df_2[(df_2['ë‚ ì§œ'].dt.date >= september_1) & (df_2['ë‚ ì§œ'].dt.date <= day0)]['ë°°ë¶„'].sum())
            ]
            
            q3_total_mail = sum(q3_monthly_data[m][0] for m in ['7', '8', '9'])
            q3_total_apply = sum(q3_monthly_data[m][1] for m in ['7', '8', '9'])
            q3_total_distribute = sum(q3_monthly_data[m][2] for m in ['7', '8', '9'])
            
            q3_target = 10000
            q3_progress = q3_total_mail / q3_target if q3_target > 0 else 0
            
            retail_df_data = {
                '7': ['', q3_monthly_data['7'][0], q3_monthly_data['7'][1], '', q3_monthly_data['7'][2]],
                '8': ['', q3_monthly_data['8'][0], q3_monthly_data['8'][1], '', q3_monthly_data['8'][2]],
                '9': ['', q3_monthly_data['9'][0], q3_monthly_data['9'][1], '', q3_monthly_data['9'][2]],
                'ê³„': ['', q3_total_mail, q3_total_apply, 288, q3_total_distribute]
            }
            retail_index = ['íƒ€ê²Ÿ (ì§„ì²™ë¥ )', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­']
            retail_df = pd.DataFrame(retail_df_data, index=retail_index)
        else:
            # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ë‹¤ë¥¸ ê¸°ê°„ ì„ íƒ ì‹œ)
            df5_p = filter_by_period(df_5)
            df1_p = filter_by_period(df_1)
            df2_p = filter_by_period(df_2)
            mail_total = int(df5_p.shape[0])
            apply_total = int(df1_p['ê°œìˆ˜'].sum())
            distribute_total = int(df2_p['ë°°ë¶„'].sum())
            retail_df_data = {period_option: [mail_total, apply_total, distribute_total]}
            retail_index = ['íŒŒì´í”„ë¼ì¸', 'ì‹ ì²­', 'ì§€ê¸‰ì‹ ì²­']
            retail_df = pd.DataFrame(retail_df_data, index=retail_index)

        # --- HTML ë³€í™˜ ë° ìŠ¤íƒ€ì¼ë§ ---
        html_retail = retail_df.to_html(classes='custom_table', border=0, escape=False)

        # ì´ë¯¸ì§€ í˜•íƒœì— ë§ëŠ” ìŠ¤íƒ€ì¼ë§ ì ìš©
        if period_option in ['ì „ì²´', '1Q', '1ë¶„ê¸°', '2Q', '2ë¶„ê¸°', '3Q', '3ë¶„ê¸°']:
            # íƒ€ê²Ÿ ê°’ë“¤ì— ë°°ê²½ìƒ‰ ì ìš©
            target_values = ['4300', '10000']
            for target in target_values:
                html_retail = html_retail.replace(f'<td>{target}</td>', f'<td style="background-color: #f0f0f0;">{target}</td>')
            
            # ì§„ì²™ë¥  ì…€ í•˜ì´ë¼ì´íŠ¸ (ëª¨ë“  ì§„ì²™ë¥  ê°’ì— ëŒ€í•´)
            import re
            # 1Q/1ë¶„ê¸°ì—ì„œ 'íƒ€ê²Ÿ (ì§„ì²™ë¥ )' í–‰ì„ ë³‘í•©í•˜ê³  ë°°ê²½ìƒ‰ ì ìš© (3ë¶„ê¸° ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ)
            if period_option in ('1Q', '1ë¶„ê¸°'):
                target_text = f"{q1_target} ({q1_progress_rate:.1%})"
                html_retail = re.sub(
                    r'(<tr>\s*<th>íƒ€ê²Ÿ \(ì§„ì²™ë¥ \)</th>)(.*?)(</tr>)',
                    lambda m: m.group(1) + 
                                re.sub(
                                    r'<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>',
                                    f'<td\\1 colspan="4" style="background-color:#e0f7fa;">{target_text}</td>',
                                    m.group(2), count=1
                                ) + 
                                m.group(3),
                    html_retail,
                    flags=re.DOTALL
                )

            # 2Q/2ë¶„ê¸°ì—ì„œ 'íƒ€ê²Ÿ (ì§„ì²™ë¥ )' í–‰ì„ ë³‘í•©í•˜ê³  ë°°ê²½ìƒ‰ ì ìš© (3ë¶„ê¸° ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ)
            elif period_option in ('2Q', '2ë¶„ê¸°'):
                target_text = f"{q2_target} ({q2_progress_rate:.1%})"
                html_retail = re.sub(
                    r'(<tr>\s*<th>íƒ€ê²Ÿ \(ì§„ì²™ë¥ \)</th>)(.*?)(</tr>)',
                    lambda m: m.group(1) + 
                                re.sub(
                                    r'<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>',
                                    f'<td\\1 colspan="4" style="background-color:#e0f7fa;">{target_text}</td>',
                                    m.group(2), count=1
                                ) + 
                                m.group(3),
                    html_retail,
                    flags=re.DOTALL
                )

            # 3Q/3ë¶„ê¸°ì—ì„œ 'íƒ€ê²Ÿ (ì§„ì²™ë¥ )' í–‰ì„ ë³‘í•©í•˜ê³  ë°°ê²½ìƒ‰ ì ìš©
            elif period_option in ('3Q', '3ë¶„ê¸°'):
                target_text = f"{q3_target} ({q3_progress:.1%})"
                html_retail = re.sub(
                    r'(<tr>\s*<th>íƒ€ê²Ÿ \(ì§„ì²™ë¥ \)</th>)(.*?)(</tr>)',
                    lambda m: m.group(1) + 
                                re.sub(
                                    r'<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>',
                                    f'<td\\1 colspan="4" style="background-color:#e0f7fa;">{target_text}</td>',
                                    m.group(2), count=1
                                ) + 
                                m.group(3),
                    html_retail,
                    flags=re.DOTALL
                )
            
            # ë¹ˆ ì…€ë“¤ì„ ê³µë°±ìœ¼ë¡œ í‘œì‹œ
            html_retail = html_retail.replace('<td></td>', '<td style="background-color: #fafafa;">&nbsp;</td>')
            
            # 'ì „ì²´' ì„ íƒ ì‹œ Q1, Q2, Q3 ì»¬ëŸ¼ í—¤ë” í•˜ì´ë¼ì´íŠ¸
            if period_option == 'ì „ì²´':
                html_retail = re.sub(
                    r'(<th[^>]*>Q1</th>)',
                    r'<th style="background-color: #ffe0b2;">Q1</th>',
                    html_retail
                )
                html_retail = re.sub(
                    r'(<th[^>]*>Q2</th>)',
                    r'<th style="background-color: #ffe0b2;">Q2</th>',
                    html_retail
                )
                html_retail = re.sub(
                    r'(<th[^>]*>Q3</th>)',
                    r'<th style="background-color: #ffe0b2;">Q3</th>',
                    html_retail
                )

            else:
                # "ê³„" ì»¬ëŸ¼ í•˜ì´ë¼ì´íŠ¸ (ê°œë³„ ë¶„ê¸° ì„ íƒ ì‹œ)
                html_retail = re.sub(
                    r'(<th[^>]*>ê³„</th>)',
                    r'<th style="background-color: #ffe0b2;">ê³„</th>',
                    html_retail
                )
                
                # "ê³„" í–‰ì˜ ë°ì´í„° ì…€ë“¤ë„ í•˜ì´ë¼ì´íŠ¸
                html_retail = re.sub(
                    r'(<tr>\s*<th>ê³„</th>)(.*?)(</tr>)',
                    lambda m: m.group(1) + re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', m.group(2)) + m.group(3),
                    html_retail,
                    flags=re.DOTALL
                )
            

        st.markdown(html_retail, unsafe_allow_html=True)

    with col5:
        if show_monthly_summary:
           
            # ----- ë²•ì¸íŒ€ ì›”ë³„ ìš”ì•½ í—¤ë” ë° ê¸°ê°„ ì„ íƒ -----
            if viewer_option == 'ë‚´ë¶€':
                header_corp, sel_corp = st.columns([4,2])
                with header_corp:
                    st.write("##### ë²•ì¸íŒ€ ì›”ë³„ ìš”ì•½")
                with sel_corp:
                    corp_period_option = st.selectbox(
                        'ê¸°ê°„ ì„ íƒ',
                        ['ì „ì²´'],
                        index=0,
                        key='corp_period')
            else:
                st.write("##### ë²•ì¸íŒ€ ì›”ë³„ ìš”ì•½")
                corp_period_option = 'ì „ì²´'  # í…ŒìŠ¬ë¼ ì˜µì…˜ì¼ ë•ŒëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ 'ì „ì²´' ì‚¬ìš©
        
        # --- ë‚ ì§œ ë³€ìˆ˜ ì„¤ì • ---
        year = today_kst.year
        q3_apply_start = datetime(year, 6, 18).date()
        q3_distribute_start = datetime(year, 6, 18).date()
        july_end = datetime(year, 7, 31).date()
        august_start = datetime(year, 8, 1).date()
        august_end = datetime(year, 8, 31).date()

        # --- ì›”ë³„ ê³„ì‚° í•¨ìˆ˜ (ìˆ˜ì •ëœ ìµœì¢… ë¡œì§) ---
        def get_corp_period_metrics(df3_raw, df4_raw, apply_start, apply_end, distribute_start, distribute_end):
            # --- df_3 (ì§€ì›: íŒŒì´í”„ë¼ì¸, ì§€ì›ì‹ ì²­) ê³„ì‚° ---
            pipeline, apply = 0, 0
            df3 = df3_raw.copy()
            date_col_3 = 'ì‹ ì²­ ìš”ì²­ì¼'
            if not pd.api.types.is_datetime64_any_dtype(df3[date_col_3]):
                df3[date_col_3] = pd.to_datetime(df3[date_col_3], errors='coerce')
            
            mask3 = (df3[date_col_3].dt.date >= apply_start) & (df3[date_col_3].dt.date <= apply_end)
            df3_period = df3.loc[mask3]

            df3_period = df3_period[df3_period['ì ‘ìˆ˜ ì™„ë£Œ'].astype(str).str.strip().isin(['O', 'ã…‡'])]
            if 'ê·¸ë¦¬íŠ¸ ë…¸íŠ¸' in df3_period.columns:
                is_cancelled = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ', na=False)
                is_reapplied = df3_period['ê·¸ë¦¬íŠ¸ ë…¸íŠ¸'].astype(str).str.contains('ì·¨ì†Œ í›„ ì¬ì‹ ì²­', na=False)
                df3_period = df3_period[~(is_cancelled & ~is_reapplied)]
            b_col_name = df3_period.columns[1]
            df3_period = df3_period[df3_period[b_col_name].notna() & (df3_period[b_col_name] != "")]

            pipeline = int(df3_period['ì‹ ì²­ëŒ€ìˆ˜'].sum())
            mask_bulk_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] > 1
            mask_single_3 = df3_period['ì‹ ì²­ëŒ€ìˆ˜'] == 1
            apply = int(mask_bulk_3.sum() + df3_period.loc[mask_single_3, 'ì‹ ì²­ëŒ€ìˆ˜'].sum())

            # --- df_4 (ì§€ê¸‰: ì§€ê¸‰ì‹ ì²­) ê³„ì‚° ---
            distribute = 0
            df4 = df4_raw.copy()
            date_col_4 = 'ìš”ì²­ì¼ì'
            if not pd.api.types.is_datetime64_any_dtype(df4[date_col_4]):
                df4[date_col_4] = pd.to_datetime(df4[date_col_4], errors='coerce')

            mask4 = (df4[date_col_4].dt.date >= distribute_start) & (df4[date_col_4].dt.date <= distribute_end)
            df4_period = df4.loc[mask4]

            df4_period = df4_period[df4_period['ì§€ê¸‰ì‹ ì²­ ì™„ë£Œ ì—¬ë¶€'].astype(str).str.strip() == 'ì™„ë£Œ']
            unique_df4_period = df4_period.drop_duplicates(subset=['ì‹ ì²­ë²ˆí˜¸'])

            mask_bulk_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] > 1
            mask_single_4 = unique_df4_period['ì ‘ìˆ˜ëŒ€ìˆ˜'] == 1
            # ë²Œí¬ ê±´ì˜ 'ëŒ€ìˆ˜ í•©'ì´ ì•„ë‹Œ 'ê±´ìˆ˜ í•©'ì„ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
            distribute = int(mask_bulk_4.sum() + unique_df4_period.loc[mask_single_4, 'ì ‘ìˆ˜ëŒ€ìˆ˜'].sum())

            return pipeline, apply, distribute

        # --- ì›”ë³„ ë°ì´í„° ê³„ì‚° ì‹¤í–‰ ---
        july_pipeline, july_apply, july_distribute = get_corp_period_metrics(
            df_3, df_4, q3_apply_start, july_end, q3_distribute_start, july_end
        )

        august_pipeline, august_apply, august_distribute = get_corp_period_metrics(
            df_3, df_4, august_start, august_end, august_start, august_end
        )
        # --- ë°ì´í„°í”„ë ˆì„ ìƒì„± ---
        corp_df_data = {
            '7ì›”': ['', july_pipeline, july_apply, '', july_distribute],
            '8ì›”': ['', august_pipeline, august_apply, '', august_distribute]
        }
        corp_df = pd.DataFrame(corp_df_data, index=['íƒ€ê²Ÿ (ì§„ì²™ë¥ )', 'íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ì·¨ì†Œ', 'ì§€ê¸‰ì‹ ì²­'])
        corp_df['ê³„'] = corp_df['7ì›”'] + corp_df['8ì›”']

        # --- 'íƒ€ê²Ÿ (ì§„ì²™ë¥ )' ë°ì´í„° ê³„ì‚° ---
        q3_target_corp = 1500
        ttl_apply_corp = corp_df.loc['ì§€ì›ì‹ ì²­ì™„ë£Œ', 'ê³„']
        progress_rate_corp = ttl_apply_corp / q3_target_corp if q3_target_corp > 0 else 0
        formatted_progress_corp = f"{progress_rate_corp:.2%}"
        target_text = f"{q3_target_corp} ({formatted_progress_corp})"

        # --- HTMLë¡œ ë³€í™˜ ë° ìŠ¤íƒ€ì¼ ì ìš© ---
        html_corp = corp_df.to_html(classes='custom_table', border=0, escape=False)
        
        # 'íƒ€ê²Ÿ (ì§„ì²™ë¥ )' í–‰ì„ ë³‘í•©í•˜ê³  ë°°ê²½ìƒ‰ ì ìš© (col4ì™€ ë™ì¼í•œ ë°©ì‹)
        import re
        html_corp = re.sub(
            r'(<tr>\s*<th>íƒ€ê²Ÿ \(ì§„ì²™ë¥ \)</th>)(.*?)(</tr>)',
            lambda m: m.group(1) + 
                        re.sub(
                            r'<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>\s*<td([^>]*)>([^<]*)</td>',
                            f'<td\\1 colspan="5" style="background-color:#e0f7fa;">{target_text}</td>',
                            m.group(2), count=1
                        ) + 
                        m.group(3),
            html_corp,
            flags=re.DOTALL
        )
        
        # 'ê³„' í—¤ë”ì— ë°°ê²½ìƒ‰ ì ìš© (ë¦¬í…Œì¼ê³¼ ë™ì¼í•œ ìƒ‰ìƒ #ffe0b2)
        html_corp = re.sub(
            r'(<th[^>]*>ê³„</th>)',
            r'<th style="background-color: #ffe0b2;">ê³„</th>',
            html_corp
        )

        # ë¹ˆ ì…€ë“¤ì„ ê³µë°±ìœ¼ë¡œ í‘œì‹œ
        html_corp = html_corp.replace('<td></td>', '<td style="background-color: #fafafa;">&nbsp;</td>')
        
        if show_monthly_summary:
            st.markdown(html_corp, unsafe_allow_html=True)

    with col6:

        st.subheader("ê¸°íƒ€")
        memo_etc = load_memo_file("memo_etc.txt")
        new_etc = st.text_area(
            "",
            value=memo_etc,
            height=150,
            key="memo_etc_input"
        )
        if new_etc != memo_etc:
            save_memo_file("memo_etc.txt", new_etc)
            st.toast("ê¸°íƒ€ ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    st.markdown("<hr style='margin-top:1rem;margin-bottom:1rem;'>", unsafe_allow_html=True)

    col7, col8, col9 = st.columns([3.5,2,1.5])

    with col7:
        # --- ë¦¬í…Œì¼ ì›”ë³„ ì¶”ì´ ê·¸ë˜í”„ ---
        if viewer_option == 'ë‚´ë¶€':
            # --- months_to_show ê²°ì • ---
            def get_end_month(option):
                if option.endswith('ì›”'):
                    try:
                        return int(option[:-1])
                    except ValueError:
                        pass
                if option in ('1Q', '1ë¶„ê¸°'): return 3
                if option in ('2Q', '2ë¶„ê¸°'): return 6
                if option in ('3Q', '3ë¶„ê¸°'): return 9
                return selected_date.month
            end_month = get_end_month(period_option)
            # í˜„ì¬ ë‚ ì§œê°€ 15ì¼ ì´ì „ì´ë©´ í•´ë‹¹ ì›” ë°ì´í„° ì œì™¸
            if selected_date.day < 15 and end_month == selected_date.month:
                end_month -= 1
                # 1ì›”ì¸ ê²½ìš° 0ì´ ë˜ì§€ ì•Šë„ë¡ ë°©ì–´
                if end_month == 0:
                    end_month = 12
            start_month = 2
            months_to_show = list(range(start_month, end_month + 1))
            # 15ì¼ ì´ì „ì´ë©´ í•´ë‹¹ ì›”ì„ ì œì™¸ (3Q í¬í•¨ ëª¨ë“  ê²½ìš°ì— ì ìš©)
            if selected_date.day < 15:
                months_to_show = [m for m in months_to_show if m < selected_date.month]
            if months_to_show:
                # ì›”ë³„ íŒŒì´í”„ë¼ì¸(ë©”ì¼) ê±´ìˆ˜ ì§‘ê³„ - 6ì›”ê³¼ 7ì›” íŠ¹ë³„ ì²˜ë¦¬
                pipeline_counts = {}
                
                for month in months_to_show:
                    if month == 6:
                        # 6ì›”ì€ 6ì›” 23ì¼ê¹Œì§€ë§Œ ì§‘ê³„
                        june_23 = datetime(selected_date.year, 6, 23).date()
                        month_count = int(df_5[
                            (df_5['ë‚ ì§œ'].dt.year == selected_date.year) &
                            (df_5['ë‚ ì§œ'].dt.month == 6) &
                            (df_5['ë‚ ì§œ'].dt.date <= june_23)
                        ].shape[0])
                    elif month == 7:
                        # 7ì›”ì€ 6ì›” 24ì¼ë¶€í„° 7ì›” 31ì¼ê¹Œì§€ ì§‘ê³„
                        june_24 = datetime(selected_date.year, 6, 24).date()
                        july_31 = datetime(selected_date.year, 7, 31).date()
                        month_count = int(df_5[
                            (df_5['ë‚ ì§œ'].dt.date >= june_24) &
                            (df_5['ë‚ ì§œ'].dt.date <= july_31)
                        ].shape[0])
                    else:
                        # ë‹¤ë¥¸ ì›”ë“¤ì€ ì „ì²´ ì›” ì§‘ê³„
                        month_count = int(df_5[
                            (df_5['ë‚ ì§œ'].dt.year == selected_date.year) &
                            (df_5['ë‚ ì§œ'].dt.month == month)
                        ].shape[0])
                    
                    pipeline_counts[month] = month_count

                # ì°¨íŠ¸ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
                chart_df = pd.DataFrame(
                    {
                        'ì›”': months_to_show,
                        'íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜': [int(pipeline_counts.get(m, 0)) for m in months_to_show]
                    }
                )
                chart_df['ì›” ë¼ë²¨'] = chart_df['ì›”'].astype(str) + 'ì›”'

                # ë§‰ëŒ€ ê·¸ë˜í”„ (íŒŒì´í”„ë¼ì¸)
                bar = alt.Chart(chart_df).mark_bar(size=25, color='#2ca02c').encode(
                    x=alt.X('ì›” ë¼ë²¨:N', title='ì›”', sort=[f"{m}ì›”" for m in months_to_show], axis=alt.Axis(labelAngle=0)),
                    y=alt.Y('íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q', title='ê±´ìˆ˜')
                )

                # ì„  ê·¸ë˜í”„ + í¬ì¸íŠ¸
                line = alt.Chart(chart_df).mark_line(color='#FF5733', strokeWidth=2).encode(
                    x='ì›” ë¼ë²¨:N',
                    y='íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q'
                )
                point = alt.Chart(chart_df).mark_point(color='#FF5733', size=60).encode(
                    x='ì›” ë¼ë²¨:N',
                    y='íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q'
                )

                # ê°’ ë ˆì´ë¸” í…ìŠ¤íŠ¸
                text = alt.Chart(chart_df).mark_text(dy=-10, color='black').encode(
                    x='ì›” ë¼ë²¨:N',
                    y='íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q',
                    text=alt.Text('íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q')
                )

                combo_chart = (bar + line + point + text).properties(
                    title=f"{selected_date.year}ë…„ ì›”ë³„ íŒŒì´í”„ë¼ì¸ ì¶”ì´ ({start_month}ì›”~{end_month}ì›”)"
                )
                st.altair_chart(combo_chart, use_container_width=True)

    with col8:
        # --- ë²•ì¸íŒ€ ì›”ë³„ ì¶”ì´ ê·¸ë˜í”„ (ë‚´ë¶€ ë·°ì–´ ì „ìš©) ---
        if viewer_option == 'ë‚´ë¶€':
            # í˜„ì¬ ë‚ ì§œê°€ 15ì¼ ì´ì „ì´ë©´ í•´ë‹¹ ì›” ë°ì´í„° ì œì™¸
            months_to_show_corp = [7]
            pipeline_values_corp = [july_pipeline]
            
            if selected_date.day >= 15:
                months_to_show_corp.append(8)
                pipeline_values_corp.append(august_pipeline)

            corp_chart_df = pd.DataFrame(
                {
                    'ì›”': months_to_show_corp,
                    'íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜': pipeline_values_corp
                }
            )
            corp_chart_df['ì›” ë¼ë²¨'] = corp_chart_df['ì›”'].astype(str) + 'ì›”'

            # ë§‰ëŒ€ ê·¸ë˜í”„
            bar_corp = alt.Chart(corp_chart_df).mark_bar(size=25, color='#2ca02c').encode(
                x=alt.X('ì›” ë¼ë²¨:N', title='ì›”', sort=[f"{m}ì›”" for m in months_to_show_corp], axis=alt.Axis(labelAngle=0)),
                y=alt.Y('íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q', title='ê±´ìˆ˜')
            )
            # ì„  ê·¸ë˜í”„ ë° í¬ì¸íŠ¸
            line_corp = alt.Chart(corp_chart_df).mark_line(color='#FF5733', strokeWidth=2).encode(
                x=alt.X('ì›” ë¼ë²¨:N', axis=alt.Axis(labelAngle=0)),
                y='íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q'
            )
            point_corp = alt.Chart(corp_chart_df).mark_point(color='#FF5733', size=60).encode(
                x=alt.X('ì›” ë¼ë²¨:N', axis=alt.Axis(labelAngle=0)),
                y='íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q'
            )
            # ë ˆì´ë¸” í…ìŠ¤íŠ¸
            text_corp = alt.Chart(corp_chart_df).mark_text(dy=-10, color='black').encode(
                x=alt.X('ì›” ë¼ë²¨:N', axis=alt.Axis(labelAngle=0)),
                y='íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q',
                text=alt.Text('íŒŒì´í”„ë¼ì¸ ê±´ìˆ˜:Q')
            )
            
            # ì œëª© ë™ì  ì„¤ì •
            if len(months_to_show_corp) == 1:
                title_corp = f"{selected_date.year}ë…„ ë²•ì¸íŒ€ íŒŒì´í”„ë¼ì¸ ì¶”ì´ (7ì›”)"
            else:
                title_corp = f"{selected_date.year}ë…„ ë²•ì¸íŒ€ íŒŒì´í”„ë¼ì¸ ì¶”ì´ (7~8ì›”)"
                
            corp_combo = (bar_corp + line_corp + point_corp + text_corp).properties(
                title=title_corp
            )
            st.altair_chart(corp_combo, use_container_width=True)

# í´ìŠ¤íƒ€ ë·° ì‹œì‘ ë¶€ë¶„
if viewer_option == 'í´ìŠ¤íƒ€':
    # pklì—ì„œ í´ìŠ¤íƒ€ DataFrame ë¡œë“œ
    @st.cache_data
    def load_polestar_data():
        try:
            with open("preprocessed_data.pkl", "rb") as f:
                data = pickle.load(f)
            return data.get('df_pole_pipeline', pd.DataFrame()), data.get('df_pole_apply', pd.DataFrame())
        except FileNotFoundError:
            st.error("preprocessed_data.pkl íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì „ì²˜ë¦¬.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame(), pd.DataFrame()
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return pd.DataFrame(), pd.DataFrame()
    
    df_pole_pipeline, df_pole_apply = load_polestar_data()
    
    # ì›”ë³„ ì§‘ê³„ ê³„ì‚° í•¨ìˆ˜
    @st.cache_data
    def calculate_monthly_summary(pipeline_df, apply_df, selected_month):
        """ì„ íƒëœ ì›”ì˜ ë°ì´í„°ë¥¼ ê³„ì‚°"""
        month_num = int(selected_month.replace('ì›”', ''))
        
        # íŒŒì´í”„ë¼ì¸ ì›” ëˆ„ê³„
        pipeline_month_total = 0
        if not pipeline_df.empty and 'ë‚ ì§œ' in pipeline_df.columns:
            month_pipeline = pipeline_df[pipeline_df['ë‚ ì§œ'].dt.month == month_num]
            pipeline_month_total = month_pipeline['íŒŒì´í”„ë¼ì¸'].sum()
        
        # ì§€ì›ì‹ ì²­ ì›” ëˆ„ê³„
        apply_month_total = pak_month_total = cancel_month_total = unreceived_total = supplement_total = 0
        if not apply_df.empty and 'ë‚ ì§œ' in apply_df.columns:
            month_apply = apply_df[apply_df['ë‚ ì§œ'].dt.month == month_num]
            apply_month_total = month_apply['ì§€ì›ì‹ ì²­'].sum()
            pak_month_total = month_apply['PAK_ë‚´ë¶€ì§€ì›'].sum()
            cancel_month_total = month_apply['ì ‘ìˆ˜í›„ì·¨ì†Œ'].sum()
            unreceived_total = month_apply['ë¯¸ì‹ ì²­ê±´'].sum()
            supplement_total = month_apply['ë³´ì™„'].sum()
        
        return {
            'pipeline_today': 0,  # ë‹¹ì¼ ë°ì´í„°ëŠ” í˜„ì¬ 0
            'pipeline_month_total': pipeline_month_total,
            'apply_today': 0,  # ë‹¹ì¼ ë°ì´í„°ëŠ” í˜„ì¬ 0
            'apply_month_total': apply_month_total,
            'unreceived_today': 0,  # ë‹¹ì¼ ë°ì´í„°ëŠ” í˜„ì¬ 0
            'unreceived_total': unreceived_total,
            'supplement_today': 0,  # ë‹¹ì¼ ë°ì´í„°ëŠ” í˜„ì¬ 0
            'supplement_total': supplement_total,
            'cancel_today': 0,  # ë‹¹ì¼ ë°ì´í„°ëŠ” í˜„ì¬ 0
            'cancel_total': cancel_month_total,
            'pak_month_total': pak_month_total,
            'cancel_month_total': cancel_month_total
        }
    
    # ì œëª© ì˜ì—­
    st.title(f"ğŸ“Š í´ìŠ¤íƒ€ 2025 ë³´ê³ ì„œ - {today_kst.strftime('%Yë…„ %mì›” %dì¼')}")

    # í˜„í™© ìš”ì•½ (ì›” ì„ íƒ)
    header_col, select_col = st.columns([3, 1])
    with header_col:
        st.subheader("ğŸ“ˆ í˜„í™© ìš”ì•½")
    with select_col:
        month_options = ["8ì›”", "7ì›”", "6ì›”", "5ì›”", "4ì›”", "3ì›”", "2ì›”", "1ì›”"]
        selected_month_label = st.selectbox(
            "ì¡°íšŒ ì›”",
            month_options,
            index=0,
            label_visibility="collapsed",
            key="polestar_month_select"
        )

    current_month_label = f"{today_kst.month}ì›”"
    is_current_month_selected = (selected_month_label == current_month_label)

    # ì›”ë³„ ì§€í‘œ ë°ì´í„°ë¥¼ ê³„ì‚°ëœ ë°ì´í„°ë¡œ êµì²´
    current_month_data = calculate_monthly_summary(df_pole_pipeline, df_pole_apply, selected_month_label)

    # ìƒë‹¨ ìš”ì•½ ì¹´ë“œ
    if is_current_month_selected:
        metric_columns = st.columns(5)
        with metric_columns[0]:
            st.metric(label="íŒŒì´í”„ë¼ì¸", value=f"{current_month_data['pipeline_month_total']} ê±´", delta=f"{current_month_data['pipeline_today']} ê±´ (ë‹¹ì¼)")
        with metric_columns[1]:
            st.metric(label="ì§€ì›ì‹ ì²­", value=f"{current_month_data['apply_month_total']} ê±´", delta=f"{current_month_data['apply_today']} ê±´ (ë‹¹ì¼)")
        with metric_columns[2]:
            st.metric(label="ë¯¸ì ‘ìˆ˜", value=f"{current_month_data['unreceived_total']} ê±´", delta=f"{current_month_data['unreceived_today']} ê±´ (ë‹¹ì¼)", delta_color="inverse")
        with metric_columns[3]:
            st.metric(label="ë³´ì™„í•„ìš”", value=f"{current_month_data['supplement_total']} ê±´", delta=f"{current_month_data['supplement_today']} ê±´ (ë‹¹ì¼)", delta_color="inverse")
        with metric_columns[4]:
            st.metric(label="ì·¨ì†Œ", value=f"{current_month_data['cancel_total']} ê±´", delta=f"{current_month_data['cancel_today']} ê±´ (ë‹¹ì¼)", delta_color="inverse")
    else:
        metric_columns = st.columns(2)
        with metric_columns[0]:
            st.metric(label="íŒŒì´í”„ë¼ì¸", value=f"{current_month_data['pipeline_month_total']} ê±´")
        with metric_columns[1]:
            st.metric(label="ì§€ì›ì‹ ì²­", value=f"{current_month_data['apply_month_total']} ê±´")

    # ìƒì„¸ ë‚´ì—­ ë¶€ë¶„ë„ ê³„ì‚°ëœ ë°ì´í„° ì‚¬ìš©
    with st.expander("ìƒì„¸ ë‚´ì—­ ë³´ê¸°"):
        detail_row_index = ['ì§€ì›ì‹ ì²­', 'í´ìŠ¤íƒ€ ë‚´ë¶€ì§€ì›', 'ì ‘ìˆ˜ í›„ ì·¨ì†Œ']
        
        if selected_month_label == "8ì›”":
            # 8ì›”ì€ í˜„ì¬ ì›”ì´ë¯€ë¡œ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©
            detailed_second_data = {
                'ì „ì›” ì´ì›”ìˆ˜ëŸ‰': [54, 32, 0],  # íŒŒì´í”„ë¼ì¸ ì œê±°
                'ë‹¹ì¼': [0, 0, 0],  # ë‹¹ì¼ ë°ì´í„°ëŠ” ë³„ë„ ê³„ì‚° í•„ìš”
                'ë‹¹ì›”_ëˆ„ê³„': [current_month_data['apply_month_total'], 
                        current_month_data['pak_month_total'], 
                        current_month_data['cancel_month_total']]
            }
        else:
            # ê³¼ê±° ì›”ì€ ëˆ„ê³„ ë°ì´í„°ë§Œ í‘œì‹œ
            detailed_second_data = {
                'ì „ì›” ì´ì›”ìˆ˜ëŸ‰': [0, 0, 0],
                'ë‹¹ì¼': [0, 0, 0],
                'ë‹¹ì›”_ëˆ„ê³„': [current_month_data['apply_month_total'], 
                        current_month_data['pak_month_total'], 
                        current_month_data['cancel_month_total']]
            }
        
        second_detail_df = pd.DataFrame(detailed_second_data, index=detail_row_index)
        second_detail_html = second_detail_df.to_html(classes='custom_table', border=0, escape=False)

        expander_col1, expander_col2 = st.columns(2)
        with expander_col1:
            st.subheader(f"{selected_month_label} í˜„í™© (ìƒì„¸)")
            st.markdown(second_detail_html, unsafe_allow_html=True)
        with expander_col2:
            st.subheader("ë¯¸ì ‘ìˆ˜/ë³´ì™„ í˜„í™© (ìƒì„¸)")

            # ê°„ë‹¨í•œ í…Œì´ë¸”ë¡œ í‘œì‹œ (ì·¨ì†Œ ì œê±°)
            detail_summary_df = pd.DataFrame({
                'êµ¬ë¶„': ['ë¯¸ì ‘ìˆ˜', 'ë³´ì™„'],
                'ìˆ˜ëŸ‰': [
                    current_month_data['unreceived_total'],
                    current_month_data['supplement_total']
                ]
            })
            st.markdown(detail_summary_df.to_html(classes='custom_table', border=0, escape=False), unsafe_allow_html=True)

    st.markdown("---")

    # í´ìŠ¤íƒ€ ì›”ë³„ ìš”ì•½ (í‘œ + ìŠ¤íƒ€ì¼) - ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€
    st.subheader("í´ìŠ¤íƒ€ ì›”ë³„ ìš”ì•½")

    summary_row_index = ['íŒŒì´í”„ë¼ì¸', 'ì§€ì›ì‹ ì²­', 'í´ìŠ¤íƒ€ ë‚´ë¶€ì§€ì›', 'ì ‘ìˆ˜ í›„ ì·¨ì†Œ']
    monthly_summary_data = {
        '1ì›”': [72, 0, 68, 4],
        '2ì›”': [52, 27, 25, 0],
        '3ì›”': [279, 249, 20, 10],
        '4ì›”': [182, 146, 16, 20],
        '5ì›”': [332, 246, 63, 23],
        '6ì›”': [47, 29, 11, 7],
        '1~6ì›” í•©ê³„': [964, 697, 203, 64],
        '7ì›”': [140, 83, 48, 9],
        '8ì›”': [np.nan, np.nan, np.nan, np.nan],
        '9ì›”': [np.nan, np.nan, np.nan, np.nan],
        '10ì›”': [np.nan, np.nan, np.nan, np.nan],
        '11ì›”': [np.nan, np.nan, np.nan, np.nan],
        '12ì›”': [np.nan, np.nan, np.nan, np.nan],
        '7~12ì›” í•©ê³„': [140, 83, 48, 9],
        '2025 ì´í•©': [1104, 780, 251, 73]
    }
    summary_df = pd.DataFrame(monthly_summary_data, index=summary_row_index)

    html_summary = summary_df.fillna('-').to_html(classes='custom_table', border=0, escape=False)
    html_summary = re.sub(
        r'(<thead>\s*<tr>)',
        r'\1<th rowspan="2">ì²­êµ¬<br>ì„¸ê¸ˆê³„ì‚°ì„œ</th>',
        html_summary,
        count=1
    )
    html_summary = re.sub(
        r'(<tr>\s*<th>1~6ì›” í•©ê³„</th>)(.*?)(</tr>)',
        lambda m: m.group(1) + re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', m.group(2)) + m.group(3),
        html_summary,
        flags=re.DOTALL
    )
    html_summary = html_summary.replace('<th>1~6ì›” í•©ê³„</th>', '<th style="background-color:#ffe0b2;">1~6ì›” í•©ê³„</th>')
    html_summary = re.sub(
        r'(<tr>\s*<th>7~12ì›” í•©ê³„</th>)(.*?)(</tr>)',
        lambda m: m.group(1) + re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', m.group(2)) + m.group(3),
        html_summary,
        flags=re.DOTALL
    )
    html_summary = html_summary.replace('<th>7~12ì›” í•©ê³„</th>', '<th style="background-color:#ffe0b2;">7~12ì›” í•©ê³„</th>')
    html_summary = re.sub(
        r'(<th[^>]*>2025 ì´í•©</th>)',
        r'<th style="background-color:#e3f2fd;">2025 ì´í•©</th>',
        html_summary
    )
    html_summary = re.sub(
        r'(<tr>.*?)(<td[^>]*>[^<]*</td>)(\s*</tr>)',
        lambda m: re.sub(
            r'(<td[^>]*>)([^<]*)(</td>)$',
            r'<td style="background-color:#e3f2fd;">\2</td>',
            m.group(0)
        ),
        html_summary,
        flags=re.DOTALL
    )
    def color_sum_cols(match):
        row = match.group(0)
        tds = re.findall(r'(<td[^>]*>[^<]*</td>)', row)
        if len(tds) >= 14:
            tds[6] = re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', tds[6])
            tds[13] = re.sub(r'<td([^>]*)>', r'<td\1 style="background-color:#ffe0b2;">', tds[13])
            row_new = row
            for i, td in enumerate(tds):
                row_new = re.sub(r'(<td[^>]*>[^<]*</td>)', lambda m: td if m.start() == 0 else m.group(0), row_new, count=1)
            return row_new
        return row
    html_summary = re.sub(r'<tr>(.*?)</tr>', color_sum_cols, html_summary, flags=re.DOTALL)
    st.markdown(html_summary, unsafe_allow_html=True)

# --- ì§€ë„ ë·°ì–´ ---
if viewer_option == 'ì§€ë„(í…ŒìŠ¤íŠ¸)':
    # --- ì§€ë„ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
    import json
    import pandas as pd
    import plotly.express as px
    import re

    @st.cache_data
    def load_preprocessed_map(geojson_path):
        """
        ë¯¸ë¦¬ ë³‘í•©ëœ ê°€ë²¼ìš´ GeoJSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        ì´ í•¨ìˆ˜ëŠ” ë¬´ê±°ìš´ ì§€ì˜¤ë©”íŠ¸ë¦¬ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        try:
            with open(geojson_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            st.error(f"'{geojson_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess_map.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
        except Exception as e:
            st.error(f"ì§€ë„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    @st.cache_data
    def get_filtered_data(_df_6, selected_quarter):
        """
        ë¶„ê¸°ë³„ë¡œ í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if selected_quarter == 'ì „ì²´':
            return _df_6['ì§€ì—­êµ¬ë¶„'].value_counts().to_dict()
        
        filtered_df = _df_6.copy()
        filtered_df['ì‹ ì²­ì¼ì'] = pd.to_datetime(filtered_df['ì‹ ì²­ì¼ì'], errors='coerce')
        q_map = {'1Q': [1,2,3], '2Q': [4,5,6], '3Q': [7,8,9], '4Q': [10,11,12]}
        if selected_quarter in q_map:
            filtered_df = filtered_df[filtered_df['ì‹ ì²­ì¼ì'].dt.month.isin(q_map[selected_quarter])]
        
        return filtered_df['ì§€ì—­êµ¬ë¶„'].value_counts().to_dict()

    @st.cache_data
    def apply_counts_to_map(_preprocessed_map, _region_counts):
        """
        ë¯¸ë¦¬ ë³‘í•©ëœ GeoJSONì— count ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ë§¤í•‘í•©ë‹ˆë‹¤.
        """
        if not _preprocessed_map:
            return None, pd.DataFrame()

        # ì›ë³¸ GeoJSONì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©
        final_geojson = _preprocessed_map.copy()
        
        # ì§€ë„ì— ìˆëŠ” ëª¨ë“  ì§€ì—­ì˜ countë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        final_counts = {feat['properties']['sggnm']: 0 for feat in final_geojson['features']}
        unmatched_regions = set(_region_counts.keys())

        # df_6ì˜ ë°ì´í„°ë¥¼ ì§€ë„ì— ë§¤í•‘
        for region, count in _region_counts.items():
            region_str = str(region).strip()
            matched = False
            
            # Case 1: 'ì„œìš¸íŠ¹ë³„ì‹œ'ì™€ ê°™ì€ ì‹œë„ëª… ì§ì ‘ ë§¤ì¹­
            if region_str in final_counts:
                final_counts[region_str] += count
                unmatched_regions.discard(region_str)
                matched = True
            
            # Case 2 & 3: 'ìˆ˜ì›ì‹œ' -> 'ê²½ê¸°ë„ ìˆ˜ì›ì‹œ'ì™€ ê°™ì€ ì‹œêµ°êµ¬ëª… ë§¤ì¹­
            if not matched:
                for key in final_counts.keys():
                    if key.endswith(" " + region_str):
                        final_counts[key] += count
                        unmatched_regions.discard(region_str)
                        matched = True
                        break
        
        # ìµœì¢… ê³„ì‚°ëœ count ê°’ì„ GeoJSONì˜ 'value' ì†ì„±ì— ì£¼ì…
        for feature in final_geojson['features']:
            key = feature['properties']['sggnm']
            feature['properties']['value'] = final_counts.get(key, 0)
            
        unmatched_df = pd.DataFrame({
            'ì§€ì—­êµ¬ë¶„': list(unmatched_regions),
            'ì¹´ìš´íŠ¸': [_region_counts.get(r, 0) for r in unmatched_regions]
        })

        return final_geojson, unmatched_df

    @st.cache_data
    def create_korea_map(_merged_geojson, map_style, color_scale_name):
        """Plotly ì§€ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ìºì‹œ ì ìš©)"""
        if not _merged_geojson or not _merged_geojson['features']: 
            return None, pd.DataFrame()
        
        plot_df = pd.DataFrame([f['properties'] for f in _merged_geojson['features']])
        if not plot_df.empty and plot_df['value'].max() > 0:
            bins = [-1, 0, 15, 60, 100, 200, 500, 1000, 3000, float('inf')]
            labels = ["0", "1-15", "16-60", "61-100", "101-200", "201-500", "501-1000", "1001-3000", "3001+"]
        else:
            bins = [-1, 0, float('inf')]
            labels = ["0", "1+"]
        plot_df['category'] = pd.cut(plot_df['value'], bins=bins, labels=labels, right=True).astype(str)
        colors = px.colors.sequential.__getattribute__(color_scale_name)
        color_map = {label: colors[i % len(colors)] for i, label in enumerate(labels)}
        fig = px.choropleth_mapbox(
            plot_df, geojson=_merged_geojson, locations='sggnm', featureidkey='properties.sggnm',
            color='category', color_discrete_map=color_map, category_orders={'category': labels},
            mapbox_style=map_style, zoom=6, center={'lat': 36.5, 'lon': 127.5}, opacity=0.7,
            labels={'category': 'ì‹ ì²­ ê±´ìˆ˜', 'sggnm': 'ì§€ì—­'}, hover_name='sggnm', hover_data={'value': True}
        )
        fig.update_layout(height=700, margin={'r': 0, 't': 0, 'l': 0, 'b': 0}, legend_title_text='ì‹ ì²­ ê±´ìˆ˜ (êµ¬ê°„)')
        return fig, plot_df

    # --- ëŒ€í•œë¯¼êµ­ ì§€ë„ ì‹œê°í™” ì‹¤í–‰ ë¡œì§ ---
    st.header("ğŸ—ºï¸ ì§€ë„ ì‹œê°í™”")
    quarter_options = ['ì „ì²´', '1Q', '2Q', '3Q']
    selected_quarter = st.selectbox("ë¶„ê¸° ì„ íƒ", quarter_options)
    
    # ë¯¸ë¦¬ ì²˜ë¦¬ëœ ê°€ë²¼ìš´ ì§€ë„ íŒŒì¼ì„ ë¡œë“œ (ìºì‹œë¨)
    preprocessed_map = load_preprocessed_map('preprocessed_map.geojson')
    
    if preprocessed_map and not df_6.empty:
        # ë¶„ê¸°ë³„ í•„í„°ë§ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œë¨)
        region_counts = get_filtered_data(df_6, selected_quarter)
        
        # í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ì§€ë„ì— ì ìš© (ìºì‹œë¨)
        final_geojson, unmatched_df = apply_counts_to_map(preprocessed_map, region_counts)
        
        st.sidebar.header("âš™ï¸ ì§€ë„ ì„¤ì •")
        map_styles = {"ê¸°ë³¸ (ë°ìŒ)": "carto-positron", "ê¸°ë³¸ (ì–´ë‘ì›€)": "carto-darkmatter"}
        color_scales = ["Reds","Blues", "Greens", "Viridis"]
        selected_style = st.sidebar.selectbox("ì§€ë„ ìŠ¤íƒ€ì¼", list(map_styles.keys()))
        selected_color = st.sidebar.selectbox("ìƒ‰ìƒ ìŠ¤ì¼€ì¼", color_scales)
        
        # ì§€ë„ ìƒì„± (ìºì‹œë¨)
        result = create_korea_map(final_geojson, map_styles[selected_style], selected_color)
        if result:
            fig, df = result
            st.plotly_chart(fig, use_container_width=True)
            st.sidebar.metric("ì´ ì§€ì—­ ìˆ˜", len(df))
            st.sidebar.metric("ë°ì´í„°ê°€ ìˆëŠ” ì§€ì—­", len(df[df['value'] > 0]))
            st.sidebar.metric("ìµœëŒ€ ì‹ ì²­ ê±´ìˆ˜", f"{df['value'].max():,}")
            st.subheader("ë°ì´í„° í…Œì´ë¸”")
            st.dataframe(df[['sggnm', 'value']].sort_values('value', ascending=False), use_container_width=True)
            if not unmatched_df.empty:
                st.subheader("âš ï¸ ë§¤ì¹­ë˜ì§€ ì•Šì€ ì§€ì—­ ëª©ë¡")
                st.dataframe(unmatched_df, use_container_width=True)
            else:
                st.success("âœ… ëª¨ë“  ì§€ì—­ì´ ì„±ê³µì ìœ¼ë¡œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ì§€ë„ ìƒì„± ì‹¤íŒ¨.")
    else:
        st.error("ì „ì²˜ë¦¬ëœ ì§€ë„(preprocessed_map.geojson) ë˜ëŠ” df_6 ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- ì§€ìì²´ë³„ ì •ë¦¬ ---
if viewer_option == 'ë¶„ì„':

    # --- ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
    @st.cache_data
    def load_and_process_data_1():
        """
        preprocessed_data.pklì—ì„œ í…ŒìŠ¬ë¼ EV ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        ì´ í•¨ìˆ˜ëŠ” í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ì–´ ê²°ê³¼ê°€ ìºì‹œë©ë‹ˆë‹¤.
        """
        try:
            import pickle
            
            with open("preprocessed_data.pkl", "rb") as f:
                data = pickle.load(f)
            
            df = data.get("df_tesla_ev", pd.DataFrame())
            
            if df.empty:
                st.error("âŒ preprocessed_data.pklì—ì„œ í…ŒìŠ¬ë¼ EV ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ ì „ì²˜ë¦¬.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
                return pd.DataFrame()
            
            # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° ë‚ ì§œ í•„í„°ë§ ì ìš©
            date_col = next((col for col in df.columns if 'ì‹ ì²­ì¼ì' in col), None)
            if date_col:
                df = df.dropna(subset=[date_col])
            
            return df

        except FileNotFoundError:
            st.error("âŒ 'preprocessed_data.pkl' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ì „ì²˜ë¦¬.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()
        except Exception as e:
            st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            st.info("ğŸ’¡ ì „ì²˜ë¦¬.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

    # --- ë°ì´í„° ë¡œë“œ ---
    df_original = load_and_process_data_1()

    if not df_original.empty:
        # --- ë©”ì¸ ë ˆì´ì•„ì›ƒ ì„¤ì • ---
        main_col, filter_col = st.columns([0.75, 0.25])

        # --- í•„í„° ì˜ì—­ (ì˜¤ë¥¸ìª½ ì»¬ëŸ¼) ---
        with filter_col:
            with st.container():
                st.markdown("<div class='filter-container'>", unsafe_allow_html=True)
                st.header("ğŸ” ë°ì´í„° í•„í„°")
                
                default_end_date = pd.to_datetime('2025-08-06').date()
                
                # 1. ê¸°ê°„ í•„í„°
                date_col = next((col for col in df_original.columns if 'ì‹ ì²­ì¼ì' in col), None)
                min_date = df_original[date_col].min().date()
                max_date = df_original[date_col].max().date()

                # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ë¶„ë¦¬í•´ì„œ ì…ë ¥
                date_col1, date_col2 = st.columns(2)

                with date_col1:
                    start_date = st.date_input(
                        "ì‹œì‘ì¼",
                        value=min_date,
                        min_value=min_date,
                        max_value=max_date,
                        key="start_date_filter"
                    )

                with date_col2:
                    end_date = st.date_input(
                        "ì¢…ë£Œì¼",
                        value=default_end_date,
                        min_value=min_date,
                        max_value=max_date,
                        key="end_date_filter"
                    )

                # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬ ë° ë³´ì •
                if start_date > end_date:
                    st.warning("âš ï¸ ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.")
                    start_date, end_date = end_date, start_date

                # 2. ì°¨ì¢… í•„í„°
                model_options = df_original['ë¶„ë¥˜ëœ_ì°¨ì¢…'].unique().tolist()
                selected_models = st.multiselect(
                    "ì°¨ì¢… ì„ íƒ",
                    options=model_options,
                    default=model_options,
                    key="model_filter"
                )

                # 3. ì‹ ì²­ìœ í˜• í•„í„°
                applicant_options = df_original['ë¶„ë¥˜ëœ_ì‹ ì²­ìœ í˜•'].unique().tolist()
                selected_applicants = st.multiselect(
                    "ì‹ ì²­ìœ í˜• ì„ íƒ",
                    options=applicant_options,
                    default=applicant_options,
                    key="applicant_filter"
                )
                st.markdown("</div>", unsafe_allow_html=True)

        # --- í•„í„°ë§ëœ ë°ì´í„° ìƒì„± ---
        df_filtered = df_original[
            (df_original[date_col].dt.date >= start_date) &
            (df_original[date_col].dt.date <= end_date) &
            (df_original['ë¶„ë¥˜ëœ_ì°¨ì¢…'].isin(selected_models)) &
            (df_original['ë¶„ë¥˜ëœ_ì‹ ì²­ìœ í˜•'].isin(selected_applicants))
        ]

        # --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ (ì™¼ìª½ ì»¬ëŸ¼) ---
        with main_col:
            st.title("ğŸš— í…ŒìŠ¬ë¼ EV ë°ì´í„° ëŒ€ì‹œë³´ë“œ")
            st.markdown(f"**ì¡°íšŒ ê¸°ê°„:** `{start_date}` ~ `{end_date}`")
            st.markdown("---")

            # --- íƒ­ êµ¬ì„± ---
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì¢…í•© í˜„í™©", "ğŸ‘¥ ì‹ ì²­ì ë¶„ì„", "ğŸ‘¨â€ğŸ’¼ ì‘ì—…ì ë¶„ì„", "ğŸ›ï¸ ì§€ìì²´ë³„ í˜„í™© ì •ë¦¬"])

            with tab1:
                st.subheader("í•µì‹¬ ì§€í‘œ")
                
                total_count = len(df_filtered)
                model_counts = df_filtered['ë¶„ë¥˜ëœ_ì°¨ì¢…'].value_counts()
                applicant_counts = df_filtered['ë¶„ë¥˜ëœ_ì‹ ì²­ìœ í˜•'].value_counts()

                metric_cols = st.columns(4)
                metric_cols[0].metric("ì´ ì‹ ì²­ ëŒ€ìˆ˜", f"{total_count:,} ëŒ€")
                metric_cols[1].metric("Model Y", f"{model_counts.get('Model Y', 0):,} ëŒ€")
                metric_cols[2].metric("Model 3", f"{model_counts.get('Model 3', 0):,} ëŒ€")
                metric_cols[3].metric("ê°œì¸ ì‹ ì²­ ë¹„ìœ¨", f"{(applicant_counts.get('ê°œì¸', 0) / total_count * 100 if total_count > 0 else 0):.1f} %")

                st.markdown("<br>", unsafe_allow_html=True)
                
                chart_col1, chart_col2 = st.columns(2)
                with chart_col1:
                    st.subheader("ì°¨ì¢…ë³„ ë¶„í¬")
                    if not model_counts.empty:
                        fig_model = px.pie(
                            values=model_counts.values, 
                            names=model_counts.index, 
                            hole=0.4,
                            color_discrete_sequence=px.colors.sequential.Blues_r
                        )
                        fig_model.update_traces(textposition='inside', textinfo='percent+label')
                        st.plotly_chart(fig_model, use_container_width=True)
                    else:
                        st.info("ë°ì´í„° ì—†ìŒ")

                with chart_col2:
                    st.subheader("ì°¨ì¢… Ã— ì‹ ì²­ìœ í˜• êµì°¨ ë¶„ì„")
                    cross_tab = pd.crosstab(df_filtered['ë¶„ë¥˜ëœ_ì°¨ì¢…'], df_filtered['ë¶„ë¥˜ëœ_ì‹ ì²­ìœ í˜•'])
                    st.dataframe(cross_tab, use_container_width=True)

            with tab2:
                st.subheader("ì‹ ì²­ìœ í˜• ë° ì—°ë ¹ëŒ€ ë¶„ì„")
                
                analysis_cols = st.columns(2)
                with analysis_cols[0]:
                    st.markdown("##### ğŸ“‹ ì‹ ì²­ìœ í˜•ë³„ ë¶„í¬")
                    if not applicant_counts.empty:
                        fig_applicant = px.pie(
                            values=applicant_counts.values,
                            names=applicant_counts.index,
                            hole=0.4,
                            color_discrete_sequence=px.colors.sequential.Greens_r
                        )
                        fig_applicant.update_traces(textposition='inside', textinfo='percent+label')
                        st.plotly_chart(fig_applicant, use_container_width=True)
                    else:
                        st.info("ë°ì´í„° ì—†ìŒ")

                if 'ì—°ë ¹ëŒ€' in df_filtered.columns:
                    with analysis_cols[1]:
                        st.markdown("##### ğŸ“‹ ì—°ë ¹ëŒ€ë³„ ë¶„í¬ (ê°œì¸/ê°œì¸ì‚¬ì—…ì)")
                        personal_df = df_filtered[df_filtered['ë¶„ë¥˜ëœ_ì‹ ì²­ìœ í˜•'].isin(['ê°œì¸', 'ê°œì¸ì‚¬ì—…ì'])]
                        age_group_counts = personal_df['ì—°ë ¹ëŒ€'].value_counts()
                        
                        if not age_group_counts.empty:
                            fig_age = px.pie(
                                values=age_group_counts.values,
                                names=age_group_counts.index,
                                hole=0.4,
                                color_discrete_sequence=px.colors.sequential.Oranges_r
                            )
                            fig_age.update_traces(textposition='inside', textinfo='percent+label')
                            st.plotly_chart(fig_age, use_container_width=True)
                        else:
                            st.info("ë°ì´í„° ì—†ìŒ")

            with tab3:
                st.subheader("ì‘ì„±ìë³„ ì‘ì—… í˜„í™©")
                # ì£¼ì˜ì‚¬í•­ í•œì¤„(ì‹¬í”Œ)
                st.markdown('<span style="color:#666; font-size:14px;">â€» 5ì›” 20ì¼ ì´ì „ê¹Œì§€ëŠ” ë°°ì€ì˜, ì´ê²½êµ¬ ê³„ì •ìœ¼ë¡œ ë§¤í¬ë¡œ ì‘ì—…ì´ ë§ì•˜ìŠµë‹ˆë‹¤.</span>', unsafe_allow_html=True)
                
                if 'ì‘ì„±ì' in df_filtered.columns:
                    # ì‘ì„±ìë³„ í†µê³„
                    writer_counts = df_filtered['ì‘ì„±ì'].value_counts()
                    
                    # ìƒìœ„ 10ëª…ë§Œ í‘œì‹œ (ë„ˆë¬´ ë§ìœ¼ë©´ ì°¨íŠ¸ê°€ ë³µì¡í•´ì§)
                    top_writers = writer_counts.head(10)
                    others_count = writer_counts.iloc[10:].sum() if len(writer_counts) > 10 else 0
                    
                    if others_count > 0:
                        # ìƒìœ„ 10ëª… + ê¸°íƒ€ë¡œ êµ¬ì„±
                        display_data = pd.concat([
                            top_writers,
                            pd.Series({'ê¸°íƒ€': others_count})
                        ])
                    else:
                        display_data = top_writers
                    
                    # ë©”íŠ¸ë¦­ í‘œì‹œ
                    metric_cols = st.columns(4)
                    metric_cols[0].metric("ì´ ì‘ì„±ì ìˆ˜", f"{len(writer_counts):,} ëª…")
                    metric_cols[1].metric("ìµœë‹¤ ì‘ì„±ì", f"{writer_counts.iloc[0] if not writer_counts.empty else 0:,} ê±´")
                    metric_cols[2].metric("í‰ê·  ì‘ì„± ê±´ìˆ˜", f"{writer_counts.mean():.1f} ê±´")
                    metric_cols[3].metric("ìƒìœ„ 10ëª… ë¹„ìœ¨", f"{(top_writers.sum() / len(df_filtered) * 100):.1f} %")
                    
                    st.markdown("<br>", unsafe_allow_html=True)
                    
                    # íŒŒì´ì°¨íŠ¸
                    chart_col1, chart_col2 = st.columns(2)
                    
                    with chart_col1:
                        st.markdown("##### ğŸ“Š ì‘ì„±ìë³„ ì‘ì—… ë¶„í¬")
                        if not display_data.empty:
                            fig_writer = px.pie(
                                values=display_data.values,
                                names=display_data.index,
                                hole=0.4,
                                color_discrete_sequence=px.colors.sequential.Purples_r
                            )
                            fig_writer.update_traces(textposition='inside', textinfo='percent+label')
                            st.plotly_chart(fig_writer, use_container_width=True)
                        else:
                            st.info("ë°ì´í„° ì—†ìŒ")
                    
                    with chart_col2:
                        st.markdown("##### ğŸ“‹ ìƒìœ„ ì‘ì„±ì í˜„í™©")
                        writer_stats_df = pd.DataFrame({
                            'ì‘ì„±ì': top_writers.index,
                            'ì‘ì„± ê±´ìˆ˜': top_writers.values,
                            'ë¹„ìœ¨(%)': (top_writers.values / len(df_filtered) * 100).round(1)
                        })
                        
                        st.dataframe(
                            writer_stats_df,
                            use_container_width=True,
                            hide_index=True
                        )
                    
                else:
                    st.warning("âš ï¸ 'ì‘ì„±ì' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("í˜„ì¬ íŒŒì¼ì˜ ì»¬ëŸ¼ëª…:", list(df_filtered.columns))

            with tab4:
                st.markdown("""
                <div style="text-align: center; padding: 20px 0; border-bottom: 2px solid #e0e0e0; margin-bottom: 30px;">
                    <h2 style="color: #1f77b4; margin: 0; font-weight: 600;">ğŸ›ï¸ ì§€ìì²´ë³„ í˜„í™© ì •ë¦¬</h2>
                    <p style="color: #666; margin: 10px 0 0 0; font-size: 16px;">ì§€ì—­ë³„ ë³´ì¡°ê¸ˆ í˜„í™© ë° í•„ìš” ì„œë¥˜ ì •ë³´</p>
                </div>
                """, unsafe_allow_html=True)
                if df_master.empty or 'ì§€ì—­' not in df_master.columns:
                    st.warning("ì§€ìì²´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    region_list = df_master['ì§€ì—­'].dropna().unique().tolist()
                    # ìˆ˜ì •ëœ ì½”ë“œ
                    st.markdown("##### ğŸ“ ë¶„ì„ ëŒ€ìƒ ì§€ì—­")
                    selected_region = st.selectbox(
                        "ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”",
                        options=region_list,
                        index=0,
                        help="ë¶„ì„í•  ì§€ìì²´ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                    )
                    st.markdown(f"**ì„ íƒëœ ì§€ì—­:** `{selected_region}`")

                    # ì„ íƒëœ ì§€ì—­ì˜ ë°ì´í„° ì¶”ì¶œ (í•œ í–‰)
                    filtered = df_master[df_master['ì§€ì—­'] == selected_region].iloc[0]

                    # --- 1. í˜„í™© (ì°¨ëŸ‰ ëŒ€ìˆ˜) ---
                    st.markdown("### ğŸ“Š í˜„í™© (ì°¨ëŸ‰ ëŒ€ìˆ˜)")
                    st.markdown("---")

                    # ë¨¼ì € ë³€ìˆ˜ë“¤ì„ ê³„ì‚°
                    general_status = filtered.get('í˜„í™©_ì¼ë°˜', 0)
                    try:
                        if pd.isna(general_status) or general_status == '' or str(general_status).strip() == '':
                            general_status = 0
                        else:
                            general_status = int(float(str(general_status).replace(',', '')))
                    except (ValueError, TypeError):
                        general_status = 0

                    priority_status = filtered.get('í˜„í™©_ìš°ì„ ', 0)
                    try:
                        if pd.isna(priority_status) or priority_status == '' or str(priority_status).strip() == '':
                            priority_status = 0
                        else:
                            priority_status = int(float(str(priority_status).replace(',', '')))
                    except (ValueError, TypeError):
                        priority_status = 0

                    # ê·¸ ë‹¤ìŒì— HTML í‘œì‹œ
                    status_cols = st.columns(2)
                    with status_cols[0]:
                        st.markdown("""
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                    padding: 20px; border-radius: 15px; color: white; text-align: center;">
                            <h4 style="margin: 0 0 10px 0; font-size: 18px;">ì¼ë°˜ í˜„í™©</h4>
                            <h2 style="margin: 0; font-size: 32px; font-weight: 700;">{general_status:,} ëŒ€</h2>
                        </div>
                        """.format(general_status=general_status), unsafe_allow_html=True)

                    with status_cols[1]:
                        st.markdown("""
                        <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
                                    padding: 20px; border-radius: 15px; color: white; text-align: center;">
                            <h4 style="margin: 0 0 10px 0; font-size: 18px;">ìš°ì„  í˜„í™©</h4>
                            <h2 style="margin: 0; font-size: 32px; font-weight: 700;">{priority_status:,} ëŒ€</h2>
                        </div>
                        """.format(priority_status=priority_status), unsafe_allow_html=True)

                    st.markdown("---")

                    # --- 2. ëª¨ë¸ë³„ ë³´ì¡°ê¸ˆ ---
                    st.subheader("ğŸš— ëª¨ë¸ë³„ ë³´ì¡°ê¸ˆ (ë‹¨ìœ„: ë§Œ ì›)")

                    # ëª¨ë¸ëª…ê³¼ ì»¬ëŸ¼ëª… ë§¤í•‘
                    model_cols = {
                        'Model 3 RWD': 'Model 3 RWD_ê¸°ë³¸',
                        'Model 3 RWD (2024)': 'Model 3 RWD(2024)_ê¸°ë³¸',
                        'Model 3 LongRange': 'Model 3 LongRange_ê¸°ë³¸',
                        'Model 3 Performance': 'Model 3 Performance_ê¸°ë³¸',
                        'Model Y New RWD': 'Model Y New RWD_ê¸°ë³¸',
                        'Model Y New LongRange': 'Model Y New LongRange_ê¸°ë³¸'
                    }

                    # ë³´ì¡°ê¸ˆ ë°ì´í„° ìˆ˜ì§‘
                    subsidy_data = []
                    for model_name, col_name in model_cols.items():
                        if col_name in filtered.index:
                            subsidy_value = filtered[col_name]
                            try:
                                if pd.notna(subsidy_value) and subsidy_value != '' and str(subsidy_value).strip() != '':
                                    numeric_value = float(str(subsidy_value).replace(',', ''))
                                    if numeric_value > 0:
                                        subsidy_data.append((model_name, numeric_value))
                            except (ValueError, TypeError):
                                continue

                    if subsidy_data:
                        # 3ì—´ ê·¸ë¦¬ë“œë¡œ í‘œì‹œ
                        cols = st.columns(3)
                        for idx, (model_name, amount) in enumerate(subsidy_data):
                            with cols[idx % 3]:
                                st.markdown(f"""
                                <div style="background: #f8f9fa; padding: 10px; border-radius: 8px; 
                                            border-left: 3px solid #007bff; margin: 5px 0;">
                                    <h6 style="margin: 0 0 5px 0; color: #495057; font-size: 12px; font-weight: 600;">{model_name}</h6>
                                    <h4 style="margin: 0; color: #007bff; font-size: 18px; font-weight: 600;">
                                        {int(amount):,} ë§Œì›
                                    </h4>
                                </div>
                                """, unsafe_allow_html=True)
                    else:
                        st.info("í•´ë‹¹ ì§€ì—­ì˜ ëª¨ë¸ë³„ ë³´ì¡°ê¸ˆ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    st.markdown("---")

                    # --- 3. í•„ìš” ì„œë¥˜ ---
                    st.subheader("ğŸ“ í•„ìš” ì„œë¥˜")
                    doc_cols = st.columns(2)

                    with doc_cols[0]:
                        st.markdown("##### ì§€ì›ì‹ ì²­ì„œë¥˜")
                        doc_text_apply = str(filtered.get('ì§€ì›ì‹ ì²­ì„œë¥˜', 'ë‚´ìš© ì—†ìŒ')).replace('\n', '<br>')
                        st.markdown(
                            f"<div style='background-color:#f0f2f6; border-radius:10px; padding:15px; height: 300px; overflow-y: auto;'>{doc_text_apply}</div>",
                            unsafe_allow_html=True
                        )

                    with doc_cols[1]:
                        st.markdown("##### ì§€ê¸‰ì‹ ì²­ì„œë¥˜")
                        doc_text_payment = str(filtered.get('ì§€ê¸‰ì‹ ì²­ì„œë¥˜', 'ë‚´ìš© ì—†ìŒ')).replace('\n', '<br>')
                        st.markdown(
                            f"<div style='background-color:#f0f2f6; border-radius:10px; padding:15px; height: 300px; overflow-y: auto;'>{doc_text_payment}</div>",
                            unsafe_allow_html=True
                        )

    else:
        st.warning("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")



    
