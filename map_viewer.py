import streamlit as st
import pandas as pd
import json
import plotly.express as px
import re

@st.cache_data
def load_preprocessed_map(geojson_path):
    """
    ë¯¸ë¦¬ ë³‘í•©ëœ ê°€ë²¼ìš´ GeoJSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” ë¬´ê±°ìš´ ì§€ì˜¤ë©”íŠ¸ë¦¬ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        with open(geojson_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        st.error(f"'{geojson_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess_map.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"ì§€ë„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data
def get_filtered_data_optimized(data, selected_quarter):
    """ì‚¬ì „ ê³„ì‚°ëœ ë¶„ê¸°ë³„ ë°ì´í„°ì—ì„œ ë°”ë¡œ ë°˜í™˜"""
    quarterly_counts = data.get("quarterly_region_counts", {})
    return quarterly_counts.get(selected_quarter, {})
    
@st.cache_data
def apply_counts_to_map_optimized(_preprocessed_map, _region_counts):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ GeoJSON ë§¤í•‘"""
    if not _preprocessed_map:
        return None, pd.DataFrame()

    # ê¹Šì€ ë³µì‚¬ ëŒ€ì‹  ì°¸ì¡°ë¡œ ì²˜ë¦¬í•˜ê³  í•„ìš”í•œ ë¶€ë¶„ë§Œ ìˆ˜ì •
    final_geojson = {
        'type': _preprocessed_map['type'],
        'features': []
    }
    
    # ì§€ì—­ë³„ ì¹´ìš´íŠ¸ ë§µ ìƒì„± (í•œ ë²ˆë§Œ)
    region_count_map = _region_counts
    unmatched_regions = set(_region_counts.keys())
    
    for feature in _preprocessed_map['features']:
        new_feature = {
            'type': feature['type'],
            'geometry': feature['geometry'],  # ì§€ì˜¤ë©”íŠ¸ë¦¬ëŠ” ì°¸ì¡°ë§Œ
            'properties': feature['properties'].copy()  # ì†ì„±ë§Œ ë³µì‚¬
        }
        
        region_name = new_feature['properties']['sggnm']
        matched_count = 0
        
        # ì§ì ‘ ë§¤ì¹­
        if region_name in region_count_map:
            matched_count = region_count_map[region_name]
            unmatched_regions.discard(region_name)
        else:
            # 1) ê¸°ì¡´: '... {ì‹œ}'ë¡œ ëë‚˜ëŠ” ê²½ìš°
            for region, count in region_count_map.items():
                if region_name.endswith(" " + region):
                    matched_count = count
                    unmatched_regions.discard(region)
                    break

            # 2) ë³´ê°•: ì§€ë„ í‚¤ì˜ ì‹œ ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì„œ ë™ì¼ ì‹œë¡œ ë§¤ì¹­
            if matched_count == 0:
                # 'ê²½ê¸°ë„ ë¶€ì²œì‹œì†Œì‚¬êµ¬' â†’ 'ë¶€ì²œì‹œì†Œì‚¬êµ¬' â†’ 'ë¶€ì²œì‹œ'
                key_body = region_name.split(" ", 1)[1] if " " in region_name else region_name
                m = re.search(r'(.+?ì‹œ)', str(key_body))
                map_city_base = m.group(1) if m else key_body
                if map_city_base in region_count_map:
                    matched_count = region_count_map[map_city_base]
                    unmatched_regions.discard(map_city_base)
        
        new_feature['properties']['value'] = matched_count
        final_geojson['features'].append(new_feature)
    
    unmatched_df = pd.DataFrame({
        'ì§€ì—­êµ¬ë¶„': list(unmatched_regions),
        'ì¹´ìš´íŠ¸': [region_count_map.get(r, 0) for r in unmatched_regions]
    })

    return final_geojson, unmatched_df

@st.cache_data
def create_korea_map(_merged_geojson, map_style, color_scale_name):
    """Plotly ì§€ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ìºì‹œ ì ìš©)"""
    if not _merged_geojson or not _merged_geojson['features']: 
        return None, pd.DataFrame()
    
    plot_df = pd.DataFrame([f['properties'] for f in _merged_geojson['features']])
    if not plot_df.empty and plot_df['value'].max() > 0:
        bins = [-1, 0, 15, 60, 100, 200, 500, 1000, 3000, float('inf')]
        labels = ["0", "1-15", "16-60", "61-100", "101-200", "201-500", "501-1000", "1001-3000", "3001+"]
    else:
        bins = [-1, 0, float('inf')]
        labels = ["0", "1+"]
    plot_df['category'] = pd.cut(plot_df['value'], bins=bins, labels=labels, right=True).astype(str)
    colors = px.colors.sequential.__getattribute__(color_scale_name)
    color_map = {label: colors[i % len(colors)] for i, label in enumerate(labels)}
    fig = px.choropleth_mapbox(
        plot_df, geojson=_merged_geojson, locations='sggnm', featureidkey='properties.sggnm',
        color='category', color_discrete_map=color_map, category_orders={'category': labels},
        mapbox_style=map_style, zoom=6, center={'lat': 36.5, 'lon': 127.5}, opacity=0.7,
        labels={'category': 'ì‹ ì²­ ê±´ìˆ˜', 'sggnm': 'ì§€ì—­'}, hover_name='sggnm', hover_data={'value': True}
    )
    fig.update_layout(height=700, margin={'r': 0, 't': 0, 'l': 0, 'b': 0}, legend_title_text='ì‹ ì²­ ê±´ìˆ˜ (êµ¬ê°„)')
    return fig, plot_df

def show_map_viewer(data, df_6):

    # --- ëŒ€í•œë¯¼êµ­ ì§€ë„ ì‹œê°í™” ì‹¤í–‰ ë¡œì§ ---
    st.header("ğŸ—ºï¸ ì§€ë„ ì‹œê°í™”")
    quarter_options = ['ì „ì²´', '1Q', '2Q', '3Q']
    selected_quarter = st.selectbox("ë¶„ê¸° ì„ íƒ", quarter_options)
    
    # ë¯¸ë¦¬ ì²˜ë¦¬ëœ ê°€ë²¼ìš´ ì§€ë„ íŒŒì¼ì„ ë¡œë“œ (ìºì‹œë¨)
    preprocessed_map = load_preprocessed_map('preprocessed_map.geojson')
    
    if preprocessed_map and not df_6.empty:
        # ë¶„ê¸°ë³„ í•„í„°ë§ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œë¨)
        region_counts = get_filtered_data_optimized(data, selected_quarter)
        
        # í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ì§€ë„ì— ì ìš© (ìºì‹œë¨)
        final_geojson, unmatched_df = apply_counts_to_map_optimized(preprocessed_map, region_counts)
        
        st.sidebar.header("âš™ï¸ ì§€ë„ ì„¤ì •")
        map_styles = {"ê¸°ë³¸ (ë°ìŒ)": "carto-positron", "ê¸°ë³¸ (ì–´ë‘ì›€)": "carto-darkmatter"}
        color_scales = ["Reds","Blues", "Greens", "Viridis"]
        selected_style = st.sidebar.selectbox("ì§€ë„ ìŠ¤íƒ€ì¼", list(map_styles.keys()))
        selected_color = st.sidebar.selectbox("ìƒ‰ìƒ ìŠ¤ì¼€ì¼", color_scales)
        


        # ì§€ë„ ìƒì„± (ìºì‹œë¨)
        result = create_korea_map(final_geojson, map_styles[selected_style], selected_color)
        if result:
            fig, df = result
            st.plotly_chart(fig, use_container_width=True)
            st.sidebar.metric("ì´ ì§€ì—­ ìˆ˜", len(df))
            st.sidebar.metric("ë°ì´í„°ê°€ ìˆëŠ” ì§€ì—­", len(df[df['value'] > 0]))
            st.sidebar.metric("ìµœëŒ€ ì‹ ì²­ ê±´ìˆ˜", f"{df['value'].max():,}")
            st.subheader("ë°ì´í„° í…Œì´ë¸”")

            # ê°’ ìœ ë¬´ì— ë”°ë¼ ë¶„í• 
            df_nonzero = df[df['value'] > 0][['sggnm', 'value']].sort_values('value', ascending=False)
            df_zero = df[df['value'] == 0][['sggnm', 'value']].sort_values('sggnm')

            # value > 0 í…Œì´ë¸” (ê¸°ì¡´ ìƒë‹¨ í…Œì´ë¸” ëŒ€ì²´)
            if not df_nonzero.empty:
                st.dataframe(df_nonzero, use_container_width=True)
            else:
                st.info("value > 0 ì¸ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")

            # value = 0 í…Œì´ë¸” (ì•„ë˜ ë³„ë„ ì„¹ì…˜)
            if not df_zero.empty:
                st.markdown("---")
                st.subheader("ê°’ 0 ì§€ì—­ ëª©ë¡")
                html_zero = df_zero.to_html(classes='custom_table', border=0, index=False)
                st.markdown(html_zero, unsafe_allow_html=True)
            else:
                st.info("value = 0 ì¸ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ì‚¬ì´ë“œë°” ë©”íŠ¸ë¦­(ì¶”ê°€)
            st.sidebar.metric("ê°’ 0 ì§€ì—­ ìˆ˜", len(df_zero))

            # ë§¤ì¹­ë˜ì§€ ì•Šì€ ì§€ì—­
            if not unmatched_df.empty:
                st.subheader("âš ï¸ ë§¤ì¹­ë˜ì§€ ì•Šì€ ì§€ì—­ ëª©ë¡")
                st.dataframe(unmatched_df, use_container_width=True)
            else:
                st.success("âœ… ëª¨ë“  ì§€ì—­ì´ ì„±ê³µì ìœ¼ë¡œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ì§€ë„ ë·°ì–´ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë©”ì¸ í•¨ìˆ˜"""
    import pickle
    import pytz
    from datetime import datetime
    
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="ì§€ë„ ë·°ì–´",
        page_icon="ğŸ—ºï¸",
        layout="wide"
    )
    
    # ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì¶”ê°€
    st.markdown("""
    <style>
        /* ê¸°ë³¸ í…Œì´ë¸” ìŠ¤íƒ€ì¼ */
        .custom_table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.9rem;
        }
        .custom_table th, .custom_table td {
            border: 1px solid #e0e0e0;
            padding: 8px;
            text-align: center;
        }
        .custom_table th {
            background-color: #f7f7f9;
            font-weight: bold;
        }
        .custom_table tr:nth-child(even) {
            background-color: #fafafa;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # ë°ì´í„° ë¡œë”©
    @st.cache_data(ttl=3600)
    def load_data():
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            with open("preprocessed_data.pkl", "rb") as f:
                return pickle.load(f)
        except FileNotFoundError:
            st.error("ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼(preprocessed_data.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë¨¼ì € 'ì „ì²˜ë¦¬.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            return {}
    
    # ë°ì´í„° ë¡œë“œ
    data = load_data()
    
    if data:
        df_6 = data.get("df_6", pd.DataFrame())
        # ì§€ë„ ë·°ì–´ ì‹¤í–‰
        show_map_viewer(data, df_6)
    else:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

if __name__ == "__main__":
    main()